\documentclass{aamas2012}
\usepackage{multirow}
%\usepackage{amsmath}
%\usepackage{amsthm}  
%\usepackage{amssymb} 
\usepackage{tkz-2d}
\usepackage{tikz}
\usepackage{tkz-berge}  
\usepackage{subfigure}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{xcolor} 
\usepackage{times} 
\usepackage{amsthm}
\usepackage{tweaklist}
%\usepackage{thm-restate}
\pdfpagewidth=8.5truein
\pdfpageheight=11truein 
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{observation}{Observation}
\newtheorem{proposition}{Proposition}
\renewcommand{\baselinestretch}{0.97}
\renewcommand{\columnsep}{1.6pc}
\newcommand{\footnoteremember}[2]{
  \footnote{#2}
  \newcounter{#1}
  \setcounter{#1}{\value{footnote}}

} \newcommand{\footnoterecall}[1]{

  \footnotemark[\value{#1}]

} 
\renewcommand{\itemhook}{\setlength{\topsep}{2pt}%
   \setlength{\itemsep}{2pt}   \setlength{\leftmargin}{8pt}
 }
\numberofauthors{1}

\author{
\alignauthor Paper  370
}
\title{A Message-Passing Approach to Computing Stable Coalitions on Graphs}

\begin{document}
\maketitle
\begin{abstract}
\begin{small}
Many real-life settings---such as communication networks, or
the electricity grid---require the development of decentralised mechanisms that
allow agents to organize into stable coalitions whose potential membership is
restricted by a graph. To meet these challenges, in this paper we develop a
novel graphical model representation of coalitional games over
graphs, and exploit this representation to devise decentralised algorithms
that lead to the formation of core-stable coalition structures. For games defined
over trees, we propose an algorithm that allows agents to identify a stable
coalition structure. That is, it determines an optimal coalition structure along with a payoff
allocation such that the resulting pair is in the core of the game. 
%Similarly,
%for arbitrary graphs, we develop an algorithm that either outputs a core
%element---or, alternatively, detects core emptiness. 
This algorithm builds upon
well-known message passing algorithms from the GDL family
\cite{actiongdl,ecs21664} which we extend to this setting.
\end{small}
\end{abstract}

%\category{I.2.11}{Distributed Artificial Intelligence}{Multiagent Systems}

%A category including the fourth, optional field follows...
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]


%\terms{Algorithms, Economics, Theory}

%Keywords are your own choice of terms you would like the paper to be indexed by.

%\keywords{Stable coalition formation, message-passing algorithms, GDL}


\section{Introduction}
\noindent Many real-life multiagent settings, such as communication or sensor networks, or, more recently, the {\em smart electricity Grid}, can benefit
from the development of \emph{decentralised}
algorithms that allow agents to organize into stable coalitions. Moreover, it is natural in such settings to assume
that coalition membership can be restricted by some kind of graph, reflecting realistic barriers to the formation
of certain agent teams.
 
As an illustrating example, consider the need to maintain reliability of supply in the modern electricity network
while curtailing carbon emissions and costs. One key requirement in this domain
is that demand should follow supply in
order to make optimal use of intermittent sources of renewable energy, while still ensuring
that electricity generation and electricity consumption are perfectly matched~\cite{GridVision}. 
Given this, a promising demand-side management strategy is to promote the formation of coalitions among
energy consumers with near-complementary consumption restrictions, by promising them rewards for collectively ``flattening'' their joint energy
consumption curve by time-shifting around their individual consumption.
In this domain, however, geographical barriers and technological limitations,
alongside the need to respond to supply and demand imbalances occurring at a local level, imply that consumers cannot just join any coalition, but rather that  coalition membership is restricted by a graph.
Now, from the Grid's perspective, the emerging coalitions should be achieving the highest possible savings in terms of energy consumption. 
At the same time, it is desirable that coalitions should be as stable as possible, for two reasons. 
First, it is more efficient for the Grid to interact with specific entities, since this leads to operational savings and the ability to 
strike long-term binding contracts.
Second, the balance of supply and demand will, naturally, be affected if consumers keep moving from coalition to coalition, altering their consumption savings plans. 
However, consumers are rational utility maximizers, and have to be incentivised to stay in a coalition via appropriate monetary payoffs.
Clearly, it is an absolute necessity in domains like this to devise decentralised processes
to allow autonomous rational agents to join together into stable coalitions, that are also optimal from
the system designer's point of view.

 Such problems can be modelled naturally as {\em coalitional games}, where
 the following questions have to be resolved: {\em (i)} the set of coalitions with maximum collective value, that is, an optimal
 coalition structure, has to be identified; 
 and {\em (ii)} each coalition's value has to be distributed 
among its members in such way that coalition members have no incentive to break away from the identified optimal structure~\cite{osborne}.
When this happens, we say that a game outcome is in {\em the core}.

Against this background, in this paper we 
develop a novel representation scheme for coalitional games over graphs, and
exploit this to devise a novel {\em decentralised} algorithm that allows agents to find
the optimal coalition structure on arbitrary
graphs. Then, for the particular case of acyclic graphs, we show how an
extension of this decentralised algorithm allows agents to find a stable
coalition structure. 
In this way, our approach deals simultaneously with two key activities 
which are usually treated separately in
the coalition formation literature: namely, constructing an optimal coalition
structure {\em and} identifying an accompanying payoff allocation so that core-stable
elements emerge. Thus, our algorithm not only computes, but also incentivises
rational agents to form the optimal coalition structure, via providing them with
structure-stabilizing payoffs.

In more detail, our contributions are as follows. 
First, we provide
a novel graphical model representation of the coalition structure generation
problem over graphs. Second, building on this model, we show that one can use
existing algorithms in the literature based on the GDL framework
(e.g.,~\cite{actiongdl,DBLP:journals/tit/AjiM00}) to allow agents to
identify the optimal coalition structure. Third, we formulate a novel
message-passing algorithm that extends the well-known
GDL algorithm~\cite{DBLP:journals/tit/AjiM00}, and exploit our
representation to construct {\em optimal and stable} coalition structures on
tree graphs. Moreover, we stress that though in our work here we prove the correctness of the algorithm only for tree graphs, 
 the correctness of our representation is established for general graphs.
 In addition, GDL techniques are known to be capable of optimal inference in graphs containing cycles.
 Thus, unlike existing approaches, our representation and algorithm 
 provide concrete foundations for extending the solution to the problem of
 constructing stable (optimal) coalition structures to general graphs.
%The first of these algorithms,
%\emph{SCF-Trees}, is guaranteed to converge to a stable coalition structure on
%tree graphs; while \emph{SCF-Graphs} builds on \emph{SCF-Trees} to allow agents
%to compute an stable coalition structure or alternatively detect the emptiness
%of the core on \emph{general graphs}.


This paper is structured as follows. In Section
\ref{sec:background}, we review the literature and in Section
\ref{sec:representation}, we describe our novel graphical model
representation. We detail the decentralised
algorithms for computing the optimal coalition structure in Section
\ref{sec:csg_on_graphs} whereas the stable coalition formation algorithm 
is presented in Section \ref{sec:algorithm_stable_on_trees}.
%In Section \ref{sec:experiments}, we empirically evaluate
%our algorithms' performance using a simulation of the customer's energy profile
%scenario. 
Finally, Section \ref{sec:conclusions} concludes and outlines some directions
for future research.


\vspace{-0.1in}\section{Background}
\label{sec:background}
\noindent In this section, we present some essential background and position our approach
within the existing literature.

\vspace{-0.05in}\subsection{Coalitional games on graphs}


\begin{figure}[!bt]
\hspace{-0.02in}\subfigure[Game over a tree]{
	\tikzstyle{node} = [circle,line width = 1pt,text width=1.3em, text
	centered,color=black,draw] \tikzstyle{arrow} = [line width = 1 pt]
	\tikzstyle{ann} = [font=\fontsize{25}{25}\selectfont]
	\begin{center}
	\begin{tikzpicture}[scale=0.55,transform shape]
		\node[node] (0) at (-1,7) {\large$a_0$};
		\node[node]  (1) at (-1,5.5) {\large$a_1$};
		\node[node] (2) at (-1,4) {\large$a_2$};
		\path[-]
					(1) edge[arrow,sloped, above] node {} (2)
					(0) edge[arrow,sloped, above] node {} (1);
		\node at (1,5.5) {
		\large
		\begin{tabular}{ | c |  c |   }
			\hline
			$\mathcal{F}(G)$ &  $v$  \\
			\hline
			\{0,1,2\} & 2  \\
			\{0,1\} & 0.1 \\
			\{0\} & 0.1 \\
  			\{1,2\} & 1.5  \\
  			\{1\} & 0.6 \\
  			\{2\} & 0.1 \\
  			\hline
		\end{tabular}
		};
		\node at (0.5,8) {
		\large
		\begin{tabular}{  c    }
		  \large$CS^*=\{\{0,1,2\}\}$\\
		  \large$\rho=\{0.5,1.4, 0.1\}$\\
		\end{tabular}
		};
	\end{tikzpicture}
	\end{center}
	\label{fig:example_line_graph}
}
\hspace{-0.03in}\subfigure[ Representation]{
	\tikzstyle{node} = [circle,line width = 1pt,text width=2.3em,
	text centered,color=black,draw]
	\tikzstyle{factor} = [square, line width = 1pt,text width=0.3em, text
	height=0.3em, color=black, fill=black, draw]
	\tikzstyle{factor2} = [square, line width = 1pt,text width=0.3em, text
	height=0.3em, color=black, fill=white, draw]
	\tikzstyle{arrow} = [line width = 1 pt]
	\tikzstyle{ann} = [font=\fontsize{25}{25}\selectfont]
	\begin{center}
	\begin{tikzpicture}[scale=0.45,transform shape]
		\node[node] (0) at (-1.7,8) {\Large$x_0$};
		\node[node] (01) at (0,8) {\Large$x_{01}$};
		\node[node] (012) at (1.75,8) {\Large$x_{012}$};
		\node[square, dashed, text width=14em, text height=5.4em, color=black,draw] at
		(0.1,8.4){}; 
		\node[factor] (f0) at (0,9) { };
		\node at (-1.5,8.9){\Large$X_0, F_0$};
		\node[node]  (1) at (0,6) {\Large$x_1$};
		\node[factor2] (f1a01) at (0,7) { };
		\node[factor] (f1) at (0.9,6) { };
		\node[node]  (12) at (1.75,6) {\Large$x_{12}$};
		\node[square, dashed, text width=14em, text height=5.1em, color=black,draw] at
		(0.1,6.4){}; 
		\node at (-1.5,6.9){\Large$X_1, F_1$};
		\node[factor2] (f12a012) at (1.75,7) { };
		\node[factor2] (f2a12) at (1.75,5) { };
		\node[square, dashed, text width=14em, text height=5.1em, color=black,draw] at
		(0.1,4.4){}; 
		\node at (-1.5,4.9){\Large$X_2, F_2$};
		\node[node] (2) at (1.75,4) {\Large$x_2$};
		\path[-]   	(0) edge[arrow,sloped, above] node {} (f0)
					(01) edge[arrow,sloped, above] node {} (f0)
					(012) edge[arrow,sloped, above] node {} (f0)
					(1) edge[arrow,sloped, above] node {} (f1)
					(12) edge[arrow,sloped, above] node {} (f1)
					(f1a01) edge[arrow,sloped, above] node {} (1)
					(f1a01) edge[arrow,sloped, above] node {} (01)
					(f12a012) edge[arrow,sloped, above] node {} (12)
					(f12a012) edge[arrow,sloped, above] node {} (012)
					(f2a12) edge[arrow,sloped, above] node {} (12)
					(f2a12) edge[arrow,sloped, above] node {} (2);
	\end{tikzpicture}
	\end{center}
	\label{fig:representation_line_graph}
}
\hspace{-0.02in}\subfigure[$\gamma$-Junction tree]{
	\tikzstyle{node} = [circle,line width = 1pt,text width=1.5em,
	text centered,color=black,draw]
	\tikzstyle{factor} = [square, line width = 1pt,text width=0.7em, text
	height=0.5em, color=black, fill=black, draw]
	\tikzstyle{arrow} = [line width = 1 pt]
	\tikzstyle{separator} = [fill=white, height = 0.5em]
	\tikzstyle{ann} = [font=\fontsize{25}{25}\selectfont]
	\begin{center}
	\begin{tikzpicture}[scale=0.75,transform shape]
		\node[node,label=right:{{\large$\substack{X_{\Psi_0}=\{x_0,x_{01},x_{012}\} \\
		\\ X_{C_0}=X_{\psi_0}  }$}}] (0) at (0,7.2){
		$X_{C_0}$ }; \node (s01) at (0,6.4){ $x_{01}$, $x_{012}$};
		\node[node,label=right:{{\large$\substack{X_{\psi_1}=\{x_{1},x_{12}\} \\ \cup 
		\{x_{01},x_{012}\} \\ \\  X_{C_1}=X_{\psi_1} }$}}] (1) at
		(0,5.6) { $X_{C_1}$}; \node (s12) at (0,4.8){ $x_{12}$};
		\node[node,label=right:{{\large$\substack{ X_{\psi_2}=\{x_{2}\} 
		\cup\{x_{12}\} \\ \\ X_{C_2}=X_{\psi_2}}$}}]
		(2) at (0,4) { $X_{C_2}$}; \path[-] (1) edge[arrow,sloped, above]
		node{} (s01) (0) edge[arrow,sloped, above] node{} (s01) (1) edge[arrow,sloped, above] node{} (s12) (2) edge[arrow,sloped, above] node{} (s12);
	\end{tikzpicture}
	\end{center}
	\label{fig:treedecomposition_line_graph}
}
\vspace{-0.2in}
\caption{ \label{fig:line_graph} Example of a) a game on an acyclic graph; b) a
representation of (a); and c) a junction tree of (b).}
\end{figure}

\begin{figure}[!bt]
\hspace{-0.1in}\subfigure[$G$]{
	\tikzstyle{node} = [circle,line width = 1pt,text width=1.5em, text centered,color=black,draw]
	\tikzstyle{arrow} = [line width = 1 pt]
	\tikzstyle{ann} = [font=\fontsize{25}{25}\selectfont]
	\begin{tikzpicture}[scale=0.5,transform shape]
		\node[node] (0) at (-1,7) {\large$a_0$};
		\node[node]  (1) at (-1,5.5) {\large$a_1$};
		\node[node] (2) at (-1,4) {\large$a_2$};
		\node at (0,5) { };
		\path[-]
					(1) edge[arrow,sloped, above] node {} (2)
					(0) edge[arrow,sloped, above] node {} (1)
					(0) edge[arrow,bend right, above] node {} (2);
	\label{fig:example_cycle_graph}
	\end{tikzpicture}
}
\hspace{-0.15in}\subfigure[PT]{
	\tikzstyle{node} = [circle,line width = 1pt,text width=1.5em, text centered,color=black,draw]
	\tikzstyle{arrow} = [line width = 1 pt]
	\tikzstyle{arrow2} = [line width = 1 pt,color=grey!20]
	\begin{tikzpicture}[scale=0.5,transform shape]
		\node[node] (0) at (-1,7) {\large$a_0$};
		\node[node]  (1) at (-1,5.5) {\large$a_1$};
		\node[node] (2) at (-1,4) {\large$a_2$};
		\node at (0,5) { };
		\path[<-]
					(1) edge[arrow,sloped, above] node {} (2)
					(0) edge[arrow,sloped, above] node {} (1);
	\label{fig:example_cycle_graph_pt}
	\end{tikzpicture}
}
\hspace{-0.2in}\subfigure[Representation]{
	\tikzstyle{node} = [circle,line width = 1pt,text width=2.3em,
	text centered,color=black,draw]
	\tikzstyle{factor} = [square, line width = 1pt,text width=0.3em, text
	height=0.3em, color=black, fill=black, draw]
	\tikzstyle{factor2} = [square, line width = 1pt,text width=0.3em, text
	height=0.3em, color=black, fill=white, draw]
	\tikzstyle{factor3} = [square, line width = 1pt,text width=0.3em, text
	height=0.3em, color=black, fill=black!20, draw]
	\tikzstyle{arrow} = [line width = 1 pt]
	\begin{center}
	\begin{tikzpicture}[scale=0.45,transform shape]
		\node[node] (0) at (-1.5,8) {\Large$x_0$};
		\node[node] (01) at (-0.1,8) {\Large$x_{01}$};
		\node[node] (012) at (1.6,8) {\Large$x_{012}$};
		\node[node] (02) at (3.1,8) {\Large$x_{02}$};
		\node[factor] (f0) at (1,9) { };
		\node[square, dashed, text width=17.2em, text height=5.1em, color=black,draw]
		at (0.8,8.4){}; 
		\node at (-1.2,8.9){\Large$X_0, F_0$};
		\node[node]  (1) at (-0.1,6) {\Large$x_1$};
		\node[factor2] (f1a01) at (-0.1,7) { };
		\node[factor] (f1) at (0.75,6) { };
		\node[node]  (12) at (1.6,6) {\Large$x_{12}$};
		\node[square, dashed, text width=17.2em, text height=5.1em, color=black,draw]
		at (0.8,6.4){}; 
		\node at (-1.2,6.9){\Large$X_1, F_1$};
		\node[factor2] (f12a012) at (1.6,7) { };
		\node[factor3] (f02a12) at (2.5,5) { };
		\node[factor2] (f02a2) at (3,4.5) { };
		\node[factor2] (f2a12) at (1.6,5) { };
		\node[square, dashed, text width=17.2em, text height=5.1em, color=black,draw]
		at (0.8,4.4){}; 
		\node at (-1.2,4.9){\Large$X_2, F_2$};
		%\node[square,text width=20em, text height=5em,
	%text centered,color=black,draw] (a2) at (1,4.3) { };
		\node[node] (2) at (1.6,4) {\Large$x_2$};
		\path[-]   	(0) edge[arrow,sloped, above] node {} (f0)
					(01) edge[arrow,sloped, above] node {} (f0)
					(012) edge[arrow,sloped, above] node {} (f0)
					(02) edge[arrow,sloped, above] node {} (f0)
					(1) edge[arrow,sloped, above] node {} (f1)
					(12) edge[arrow,sloped, above] node {} (f1)
					(f1a01) edge[arrow,sloped, above] node {} (1)
					(f1a01) edge[arrow,sloped, above] node {} (01)
					(f12a012) edge[arrow,sloped, above] node {} (12)
					(f12a012) edge[arrow,sloped, above] node {} (012)
					(f2a12) edge[arrow,sloped, above] node {} (12)
					(f2a12) edge[arrow,sloped, above] node {} (2)
					(f02a12) edge[arrow,sloped, above] node {} (02)
					(f02a12) edge[arrow,sloped, above] node {} (12)
					(f02a2) edge[arrow,sloped, above] node {} (02)
					(f02a2) edge[arrow,sloped, above] node {} (2);
	\end{tikzpicture}
	\end{center}
	\label{fig:representation_cycle_graph}
}
\hspace{-0.17in}\subfigure[$\gamma$-Junction tree]{
	\tikzstyle{node} = [circle,line width = 1pt,text width=1.5em,
	text centered,color=black,draw]
	\tikzstyle{factor} = [square, line width = 1pt,text width=0.7em, text
	height=0.5em, color=black, fill=black, draw]
	\tikzstyle{arrow} = [line width = 1 pt]
	\tikzstyle{separator} = [fill=white, height = 0.5em]
	\tikzstyle{ann} = [font=\fontsize{25}{25}\selectfont]
	\begin{center}
	\begin{tikzpicture}[scale=0.75,transform shape]
\node[node,label=right:{{\large$\substack{X_{\psi_0}=\{x_0,x_{01},
 x_{012},x_{02}\} \\ X_{C_0}=X_{\psi_0}}$}}] (0) at
(0,7.2){$X_{C_0}$}; 
\node (s01) at (0,6.4){ $x_{01}$, $x_{012}$, $x_{02}$};
		\node[node,label=right:{{\large$\substack{X_{\psi_1}=\{x_{1},x_{12}\}\\ \cup 
		\{x_{01},x_{012}\} \\ \\
X_{C_1}=X_{\psi_1} \cup \{x_{02}\}}$}}] (1) at (0,5.6) {$X_{C_1}$};
\node (s12) at (0,4.8){ $x_{12},x_{02}$};
\node[node,label=right:{{\large$\substack{X_{\psi_2}=\{x_2\} \cup  
\{x_{12},x_{02}\} \\ \\ X_{C_2} = X_{\psi_2}}$}}] (2) at (0,4)
{$X_{C_2}$}; \path[-] (1) edge[arrow,sloped, above] node{} (s01) (0) edge[arrow,sloped,
above] node{} (s01) (1) edge[arrow,sloped, above] node{} (s12) (2)
edge[arrow,sloped, above] node{} (s12);
	\end{tikzpicture}
	\end{center}
	\label{fig:treedecomposition_cycle_graph}
}
\vspace{-0.15in}
\caption{\label{fig:cycle_graph} Example of a) a graph with a
cycle; b) a representation of (b); and c) and junction tree of (b).}
\vspace{-0.2in}
\end{figure}

\noindent A coalitional (``transferable utility'', or ``characteristic function'') game is
traditionally defined as follows. Let $A =\{a_1,\ldots, a_n\}$ be a set of
agents. A subset $S \subseteq A$ is termed a coalition. Then, a coalitional game
$CG$ is completely defined by its {\em characteristic function}  $v: 2^A
\rightarrow \Re$ (with $v(\emptyset)=0$), which assigns a real value
representing (transferable) utility to every feasible coalition~\cite{osborne}.
Agents in a coalition are then permitted to freely distribute coalitional
utility among themselves. 
Given a game $CG$, a {\em coalition structure} $CS=
\{S_1, \ldots, S_k\}$ is an exhaustive disjoint partition of the space of agents
into coalitions. We overload notation by denoting by $v(CS)$ the (intuitive)
worth of a coalition structure: $v(CS) = \sum_{S \in CS} v(S)$. We also denote
the set of all possible coalition structures by $\mathbf{CS}$.

Assume now that feasible coalitions are determined by a {\em graph} $G$: {\em
(i)} each node of the graph represents an agent; and {\em (ii)} a coalition $S$
is allowed to form iff every two agents in $S$ are connected by some
path in the subgraph induced by $S$. We denote the set of agent nodes in $G$ by
$A(G)$. Given a set of agents $A\subseteq A(G)$ we also denote
$G_{A}$ as the subgraph of $G$ induced by $A$ and $G_{\setminus A}$ as the subgraph of $G$
induced by all the agents $A(G)$ excluding those in $A$.



\begin{definition}
A coalitional game $CG$ on a graph $G$ is a tuple $\langle A(G), v,
F(G)\rangle$ where: 
(i) $F(G)$ is the set of all {\em feasible} coalitions---i.e., coalitions permitted to form given $G$; and
(ii) $v$ is the characteristic function, defined for all coalitions in $F(G)$.
\end{definition}
An example of a game on a graph in
which three agents interact in a line is given in Figure
\ref{fig:example_line_graph}. 
Notice that $\mathbf{CS}$ is now restricted
 to the set of possible coalition structures given $F(G)$.
 Let $F_{A'}(G)$ be the set of feasible coalitions that contain some agent in
 $A'$, $F_{A'}(G)=\{S\in F(G)\vert S\cap A' \neq
 \emptyset\}$. Thus, in Figure \ref{fig:example_line_graph}
 the set of coalitions that contain $a_0$ is
 $F_{\{0\}}(G)=\{\{0\},\{0,1\},\{0,1,2\}\}$ and $a_0$ can form a coalition that
 contains itself and $a_1$ ($S=\{0,1\}$) but not a coalition with $a_2$ without
 $a_1$ (e.g. $S=\{0,2\} \not \in F_{\{0\}}(G)$).
 
%  Given a game on a graph $\langle A, v, F(G)\rangle$, a {\em coalition
%  structure} $CS = \{S_1, \ldots, S_k\}$ is a set of
% feasible ($\forall S \in CS: \ S \in F(G)$), exhaustive ($S_1 \cup
% \ldots \cup S_k \supseteq A$) disjoint ($\forall S, S' \in CS$: \ $S \cap S' \cap A
% = \emptyset$) coalitions with respect to agents in $A$.
% While the restriction of
%  $\mathbf{CS}$ to be exhaustive and disjoint {\em with respect to 
% $A$} differs from the traditional in the literature, it is
% required later on the formalisation of algorithms and proofs, to consider games
% in which the graph $G$ contains agents nodes not in $A$ ($A\subset G$). Observe
% that, if this is the case, this definition allows these \emph{ghosts} agents to
% be in more than one coalition or in no coalition at all;  while if $A=G$, the traditional setting persists.
%Also, in this
%setting we assume that if a coalition $S\in F$ does not contain any agent in
%$A$ ($A\cap S = \emptyset$) it is ignored and not considered in the game.
%Notice that $\mathbf{CS}$ is now restricted
% to the set of coalition structures possible given $F(G)$; while if the graph
% is fully connected, the traditional setting persists.





% Note
%that when $G$ is a complete graph then it correspond to the classical
%coalitional games where all coalitions are feasible \footnote{From now on we
%also assume that our graph is connected. If it is not, we can simply apply our
%findings separately on each connected component.}.

%\subsection{Coalition structure generation}

A well-studied problem, due to its apparent significance, is  the {\em coalition structure
generation (CSG) problem}, aiming to identify the
coalition structure $CS^*$ that maximizes {\em social welfare}---i.e., the coalition
structure with maximal value. As an example, in Figure \ref{fig:example_line_graph} the social welfare-maximizing structure
 is composed of a single coalition that includes all the three agents,
$CS^*=\{\{0,1,2\}\}$, with a value of $2$.
The CSG problem is known to be hard~\cite{DBLP:journals/ai/SandholmLAST99}.

%This is a well-known
%NP-hard combinatorial optimization problem for which a
%number of algorithms have been proposed in recent years.

%\subsection{Stability: the core}

Now, agents are selfish and thus need to decide how the value 
of their coalition should be distributed.
A vector $\rho = \{\rho_1, \ldots, \rho_n\}$ assigning
some payoff to each agent $a_i \in A$ is called an \emph{allocation}.
We denote the set of payments for a
subset of agents $S$, $\bigcup_{i\in S} \rho_i$, by $\rho(S)$ and the sum of
these payments, $\sum_{i\in S} \rho_i$, by $\rho_S$. An allocation $\rho$ is an
{\em imputation} for a given $CS$, if it is efficient ($\rho_S =v(S)$ for all $S \in CS$), and individually rational (that is, $\rho_i \geq v(\{i\})$ for all $a_i$). Note that if $\rho$ is an imputation for $CS$, then $\rho_A = v(CS)$. Thus, in Figure~\ref{fig:example_line_graph},
$\{\rho_1\hspace{-0.03in}=\hspace{-0.03in}\frac{2}{3},
\rho_2\hspace{-0.03in}=\hspace{-0.03in}\frac{2}{3}, \rho_3\hspace{-0.03in}
=\hspace{-0.03in}\frac{2}{3}\}$ and
$\{\rho_1\hspace{-0.03in}=\hspace{-0.03in}0.5,
\rho_2\hspace{-0.03in}=\hspace{-0.03in}1.4, \rho_3\hspace{-0.03in}
=\hspace{-0.03in}0.1\}$ are two different imputations for $CS^*=\{\{0,1,2\}\}$.
 
A game outcome is a $(CS,\rho)$ pair, assigning agents to
coalitions and allocating payoffs to agents efficiently. However, this does not
mean that a game outcome is necessarily stable: there might be agents that feel
there are outcomes that can make them better-off. This raises the question of
identifying stable outcomes. The {\em core} is arguably the main stability
solution concept in cooperative games. It is the set of coalition
structure-imputation tuples $(CS, \rho)$ such that no feasible coalition has a
deviation incentive. Formally:
%$$Core(CG) = \{ (CS,\rho) : CS \in \mathbf{CS}, \rho_A = v(CS) \ \& \ \rho_S \geq v(S) \
%\forall S \in F(G)\}
$$
Core(CG) = \{ (CS,\rho) : \rho_A = v(CS) \ \& \ \rho_{S} \geq v(S) \
\forall S \in F(G)\}
$$
%Again notice that definition of the core is slightly modified to consider games
%where $A\subset G$ for which the value of a coalition $S$ is shared only by
%agents in $A$; while if $A=G$, $S\cap A = S$,the traditional setting persists.

\noindent Thus, in Figure \ref{fig:example_line_graph} 
$\{\rho_1\hspace{-0.03in}=\hspace{-0.03in}0.5,
\rho_2\hspace{-0.03in}=\hspace{-0.03in}1.4, \rho_3\hspace{-0.03in}
=\hspace{-0.03in}0.1\}$ is in the core but 
$\{\rho_1\hspace{-0.03in}=\hspace{-0.03in}\frac{2}{3},
\rho_2\hspace{-0.03in}=\hspace{-0.03in}\frac{2}{3}, \rho_3\hspace{-0.03in}
=\hspace{-0.03in}\frac{2}{3}\}$ is not because $\frac{2}{3}\cdot 2 \leq
v(\{1,2\})\hspace{-0.03in}=\hspace{-0.03in}1.5$.

Notice that {\em only optimal coalition structures might admit an element in the core}. Intuitively, if the current structure is suboptimal
then a subset of agents can be made strictly better off by moving to an optimal coalition structure.
%and awarding the agents the marginal difference of the two structures' worth.
Note also that the core is a strong solution concept, as it is empty in a plethora of games; therefore, the question
of the core non-emptiness is key in many settings.



\vspace{-0.05in}\subsection{GDL algorithm}
\label{sec:gdl_message_passing}
\noindent GDL \cite{DBLP:journals/tit/AjiM00} is a general message-passing
algorithm that can compute a factored objective function in an efficient manner. 
%The importance
%of the GDL framework stems from unifying a family of techniques (e.g.
%Viterbi's, Pearl's belief propagation or Shafer-Shenoy algorithms to name a
%few) which have been widely used in different areas such as information theory
%or computer vision.
In particular, GDL consider a function $F$, that is dependent on $N$ variables,
$\mathcal{X}=\{x_1,\ldots,x_{\vert N \vert}\}$, and is defined as the
combination of $M$ factors $\mathcal{F}=\{f_1,\ldots,f_{\vert M \vert}\}$ such
that $F(X) = \bigotimes_{f\in \mathcal{F}} f(X_f)$ where $X_f\subseteq
\mathcal{X}$ are the variables in the scope of $f$ and $\bigotimes$ stand for
the combination (also called join) operator. The combination of two functions
$f_i$ and $f_j$ (noted $f_i\otimes f_j$) is a function defined over
$X_{f_{ij}}=X_{f_i}\cup X_{f_j}$ that joins the knowledge represented by the
individual functions into a single one by adding their values such that
$(f_i\otimes f_j)(X_{f_{ij}})= f_i(X_{f_i}) + f_j(X_{f_j})$ where $X_{f_i}$ and
$X_{f_j}$ are the projection of $X_{f_{ij}}$ over the scope of $f_i$
and $f_j$ respectively\footnote{$\bigotimes$ stands for the generalisation
of the join operator over a set of functions: $ \bigotimes_{\{f_1,
\ldots, f_{\vert M \vert} \} } = f_1 \otimes ( f_2 \otimes \ldots (f_{\vert M
\vert-1} \otimes f_{\vert M\vert}))$}. Note that since we sum functions that can
have different but overlapping scopes the join operator must perform a 
sum over the domain of the join scope rather than a simple sum.
%\footnote{\textcolor{red}{We should
%say something more about the combination operator \ldots or not }}. 
The
objective function is then to find the assignment of variables in $\mathcal{X}$
that maximize the global function: $X^*=arg \max_{X} \bigotimes_{f\in
\mathcal{F}} f(X_f)$.

 In order to ensure optimality and convergence, the factor graph must be
 compiled in a tree-like structure known as junction tree.
\begin{definition}[Junction Tree]
 A junction tree (JT) for $\langle \mathcal{X},\mathcal{F}\rangle$ is a
tree of cliques that can be represented as a triple $\langle 
\mathcal{C},\Psi,\mathcal{S}\rangle$ where:   
\begin{itemize}
\item $\mathcal{C}= \{X_{C_1},\ldots,X_{C_n}\}$ is a set of cliques, where each
clique $X_{C_i}$ is a subset of variables $X_{C_i}\subseteq \mathcal{X}$.
\item $\Psi=\{\psi_1,\ldots,\psi_n\}$ is a set of potentials, one per clique,
where a potential $\psi_i$ is defined as the combination of a set of 
 functions $\mathcal{F}_i\subseteq \mathcal{F}$, $\psi_i(X_{\psi_i}) =
 \bigotimes_{f\in \mathcal{F}_i} f(X_f)$. 
\item  $S$ is a set of separators,
where a separator $Sep_{ij}\in \mathcal{S}$ is an edge between clique $X_{C_i}$ and
$X_{C_j}$ containing their intersection, namely $Sep_{ij} = X_{C_i} \cap 
X_{C_j}$.
\end{itemize}
Furthermore, the following properties must hold: (i) {\bf (Covering)} The scope
of each potential is a subset of the clique to which it is assigned ($X_{\psi_i}
\subseteq X_{C_i}$) and each function $f\in \mathcal{F}$ is included in exactly one potential; (ii) {\bf (Running intersection)} If a variable $x_i$ is
in two cliques $X_{C_i}$ and $X_{C_j}$, then it must also be in all cliques on
the path between them.
\label{def:junctiontree}
\end{definition} 
\noindent Now, the maximisation task defined above can be solved by using a
message-passing\footnote{A message-passing procedure such that messages are
propagated serially from the leaves to the root.} procedure (the single-vertex
GDL) over a rooted $JT$ where
each clique $X_{C_i}$ exchanges a message with its
clique parent $X_{C_p}$, once it has received messages from
all its children:
\begin{equation}
\mu_{i \rightarrow p}(Sep_{ip}) = \max_{X_{C_i} \setminus Sep_{ip}}
\psi_i(X_{\psi_i}) \otimes \bigotimes_{j \in Ch_i} \mu_{j
\rightarrow i}(Sep_{ji})
\label{eq:gdl_message}
\end{equation}
where $Ch_i$ stands for $X_{C_i}$ 's children in $JT$.
% and that the set of
%cliques $\mathcal{C}= \{X_{C_1},\ldots,X_{C_n}\}$ is distributed among a set of
%agents $A=\{a_1,\ldots,a_{n}\}$, where each agent $a_i\in A$ is assigned a
%single clique $X_{C_i}$. Given a factor graph $\langle \mathcal{X},\mathcal{F}
%\rangle$, Action-GDL runs in two phases: a first phase that runs a
%single-vertex GDL message-passing over the junction tree; and a second value
%propagation phase that retrieves the optimal solution $X^*$.


\noindent Upon receiving messages from all its children, each clique $X_{C_i}$
can compute its state function (also known as belief) as:
\begin{equation}
s_i(X_{C_i}) = \psi_i(X_{\psi_i}) \otimes \bigotimes_{j \in Ch_i}
\mu_{j \rightarrow i}(Sep_{ji})
\label{eq:gdl_state_function}
\end{equation}

%After the single-vertex GDL execution is over, the state function of any clique
%$X_{C_i}\in \mathcal{C}$ summarizes its local knowledge over variables
%$X^*_{C_j}$, $s_i(X_{C_i}) = \max_{X\setminus X_{C_i}} \bigotimes_{j\in
%D_i\cup\{i\}} \psi_j(X_{C_j})$ where $D_i$ stands for the
%index of the descendants of $X_{C_i}$ in the rooted junction tree.
 
\noindent Then, once the execution of the single-vertex GDL is over, cliques can
infer the optimal values of its variables by executing a \emph{value-propagation}
phase that recursively applies from the root to the leaves: 
\begin{equation}
X^*_{C_j}= arg \max_{X_{C_j, Sep_{jp}= Sep^*_{jp}}} s_j(X_{C_j}) 
\label{eq:cliques_variables_computation}
\end{equation}
where $p$ stands for the
parent of $X_{C_i}$ and $Sep^*_{jp}$ stands for
the values of $Sep_{jp}$ variables already inferred on cliques up $X_{C_j}$.
Finally, $\bigcup_{X_{C_j} \in \mathcal{C}} X^*_{C_j}$ recovers the optimal
solution $X^*$.

The execution of single-vertex GDL require a number of
messages linear to the number of edges in the JT. The communication complexity lies in the size of messages exchanged
during the execution of single-vertex GDL, which is exponential to the
separators' sizes (the size of value messages is linear). 
The memory and the computation required by each clique $X_{C_i}\in
\mathcal{C}$ to build messages (Eq. \ref{eq:gdl_message}), compute the state
function (Eq. \ref{eq:gdl_state_function}) and find clique's optimal values (Eq.
\ref{eq:cliques_variables_computation}) is exponential to the clique's size
$\mathcal{O}(2^{\vert X_{C_i}\vert})$.

\subsection{Related Work and Discussion}

\noindent There is an abundance of papers dealing with various aspects of the coalition formation problem---some focusing
on coalition structure generation, others on the problem of allocating payoff to the agents in some fair or stable manner.
For instance, a number of algorithms have been proposed to compute
the set of optimal coalitions~\cite{ecs18491,ecs9550,ecs17179}. However, these methods
ignore the fact that individual agents---say electricity consumers---have their own preferences,
and thus need to be provided with incentives in order to form the optimal coalition structure. 
On the other hand, the provision of such incentives via the allocation of substantial payoff, has long been studied in 
cooperative games~\cite{greco_ijcai,DBLP:journals/corr/abs-1102-1747,DBLP:conf/sigecom/ConitzerS03,deng94}. 
However, relevant research to date mostly focuses on 
characterising the coalitional game outcomes, and on determining the complexity of identifying such outcomes, rather
than providing algorithms that the agents can use in order to actually form
stable coalitions. Moreover, in many occasions the optimality  of the grand coalition\footnote{The grand coalition is the coalition of all
agents.}  is assumed. Hence, the payoff allocation problem is kept (artificially) isolated from the coalition structure generation one.
In our work here, we tackle both problems simultaneously.
Furthermore, while most previous work has viewed coalition formation
as a problem to tackle in a centralized manner, not satisfying the decentralisation requirement present in many domains~\cite{ecs9550,ecs17179},
we provide a {\em decentralized} algorithm to identify core-stable (coalition structure, payoff allocation) pairs.

Now, the idea of having coalitions whose potential membership is restricted by some kind of graph
is an old one, since it naturally reflects many real-life situations.
Work in {\em network formation}, in particular, following the seminal work of Myerson~\cite{myerson77}, has attempted to solve the problem of 
{\em progressively building} stable coalitional structures in networks, through the addition and removal of links among nodes~\cite{jackson2003}.
That line of research, however, focused mostly on non-cooperative aspects of the coalition formation problem---for instance, by modelling the problem
as a bargaining game or some other type of game in extensive form.

In {\em cooperative} settings, starting with the seminal work of Deng and Papadimitriou in~\cite{deng94}, 
there has been work on graph-inspired {\em representations} for coalitional games. Such representations include
Ieong and Shoham's marginal contribution nets~\cite{ieongmcnets}, Bachrach {\em et al.}'s hypergraph-based 
representation to tackle coalition structure generation in skill games~\cite{bachrach2010}, and Brafman {\em et al.}'s work on
identifying succinct coalitional game representations to model multiagent {\em planning} problems~\cite{TUplanning}.
Moreover, there has been some work on {\em cooperative solution concepts} in graph-restricted games~\cite{brink2006,meir2011}.
However, that work has {\em not} for the most part focused on the concept of the core, neither has it attempted to address the question of how core-stable
coalitions emerge.

One exception is the work of Demange~\cite{demange2004}. She proved that when the graph restricting a game is a tree there always exists an element in the core; and,
moreover, presented a process that identifies a coalition structure and a payoff allocation that lie in the core. % of the game.
Here we extend that work, in the sense that ours is a decentralized algorithm,
defined over a novel graphical representation of the coalition formation
problem. In a clear distinction to Demange's approach, our algorithm
works on a graphical model representation which, while being a junction tree of the original
graph, is nevertheless a tree whose nodes are {\em not} agents---but, rather, variable
and function nodes of a factored graph. In this way, we effectively provide a mapping that relates solutions of the graphical model to (structure-stabilizing) solutions of the underlying coalition formation problem.

Indeed, by extending GDL our approach draws a clear connection between graphical models and
stable coalition formation.  
Importantly, GDL can be employed for optimal inference in general graphs by
making use of well known tree decomposition techniques (e.g., by compiling the
original problem into a junction tree). In addition, while here we prove the
correctness of the algorithm only for tree graphs, we do prove the correctness of our representation (and the associated mapping) for general graphs. As a result, and in contrast to other existing approaches to date, our work provides a clear intuition on how to address the problem of {\em constructing} core elements in graphs containing cycles.



\section{Problem representation}
\label{sec:representation}

\noindent In this section we propose a new representation of a coalitional game
on a graph $G$ which efficiently captures the
interactions among agents in $G$. Our representation builds on a particular type
of graphical model, called factor graph: a bipartite graph composed of two kinds
of elements: variable nodes ($\mathcal{X}$) and function nodes ($\mathcal{F}$).

Our factor graph representation requires the set of agents in $CG$ to be
arranged into a pseudotree $PT$.

 
% Next, in section
%\ref{sec:algorithms}, we will develop algorithms that executed over this
%representation find the optimal coalition structure and also a set of payments
%in the core that make this coalition structure stable.

% In this section we propose a novel representation of a coalitional game by
%means a particular type of graphical model, called factor graph. a tuple
%$\langle \mathcal{X}, \mathcal{F}\rangle$ where $\mathcal{X}$ is a set of
%discrete variables and $\mathcal{F}$ a set of real functions, called factors,
%over these variables. 

% However before introducing our novel representation, we will describe what would
% be a more straightforward representation of a coalition structure generation
% problem into a factor graph. Then we will use this representation as a
% comparison to show the compactness of our representation in coalitional games
% over factor graphs.

% \begin{definition}
% A representation of a coalitional game 
% $CG = \langle A, v, F \rangle $ is a tuple $R(CG) =\langle
% \mathcal{X}, \mathcal{F}_R = \vec{f}\cup \vec{v}\rangle$ where:
% \begin{itemize}
%   \item $\mathcal{X} = \{x_{S} \vert S \in F \}$ is a set of binary variables,
%   one per feasible coalition.
% \item  $\vec{v}=\{v_S \vert S \in F\}$ is a set of unary functions, one per
% feasible coalition, where $v_{S}$ encodes the value of coalition $S$,
% $v_{S}(x_{S}=1) = v(S)$.
% \item  $\vec{f}=\{f_i \vert a_i \in A\}$ is a set of functions, one
% per agent, where $f_i$ controls that one and only one of the coalition
% variables that include $a_i$ is activated:
% \begin{equation}
% f_i(\{ x_{S}\in \mathcal{X} \vert i \in S \})= 
% \begin{cases} 
% 0,  \ \ \ \sum\limits_{S \ni i }x_{S} = 1 \\ 
% -\infty,  \ \ \mbox{otherwise}
% \end{cases}
% \end{equation}
% \end{itemize}
% \end{definition}
% 
% 
% The optimal solution of $R(CG)$ is defined as $X^* = \arg \max_{X}
% \sum_{f\in \mathcal{F}_R}f(X)$. Given an optimal solution $X^*$, the
% optimal coalition structure $CS^*$ can be recovered from $X^*$ as follows $CS^*=\bigcup_{x_S=1 \in X^*} S$.






\begin{definition}[Pseudotree]
%A pseudotree $T$ of a graph $G$ over a set of agents $A$ is a rooted
%tree with $A$ agents as nodes and the property that any pair of two adjacent
%agents in $G$ are on the same branch of $T$.
A pseudotree
$PT$ of $G$ is a rooted tree with agents $A(G)$ as nodes and the property that
any two agents that share an edge in $G$ are on the same branch in $PT$.
%for any pair of agents $i,j \in A$ if exists any path between them in $G$
%composed of agents not in $A$ then $i,j$ are on the same
%branch\footnote{A branch stands for the path between a leaf node and the
%root node in $PT$.} in $PT$. In the case $A(G) = A$, this property reduces to:
%any two agents that share an edge in $G$ are on the same branch in $PT$.
\end{definition}

Figure \ref{fig:example_cycle_graph_pt} shows a pseudotree, rooted at agent
$a_0$, of the cycle graph $G$ in Figure \ref{fig:example_cycle_graph}. 
%Observe
%that any pseudotree of $G$ will form a line between agents in $A(G)$ because
%any pair of agents in $A(G)$ share an edge in $G$ and hence, should be placed
%in the same branch.
Let's denote $A(PT)$ the set of agent' nodes in $PT$ and with $Ch_i$ the
children, $An_i$ the ancestors and $D_i$ the descendants of $a_i\in A$. Finally,
let $PT_i$ be the subtree of $PT$ rooted at $a_i$. 
Then, in Figure \ref{fig:example_cycle_graph},
$Ch_{1}=D_{1}=\{2\}$, $An_{1}=\{0\}$ and $PT_1$ is a tree rooted at
$a_1$ composed of agents $a_1,a_2$.


Then, given a game on a graph $CG=\langle A(G), v, F(G) \rangle$ and a
pseudotree $PT$ over $G$,
the partial ordering that $PT$ defines among agents in $G$ allows us to
partition the set of feasible coalitions into $\vert A \vert$ disjoint sets $\{\mathbf{S_i}\vert
a_i \in A\}$, one per agent, where the set of coalitions $\mathbf{S_i}$
contains all the feasible coalitions that include agent $a_i$ but no agent up $a_i$ in $PT$,
$\mathbf{S_i} = F_{\{i\}}(G_{\setminus An_i}) $.

% Observe that given an agent $a_i$, its set of local coalitions
%$F_{\{i\}}(G_{\setminus \bar{PT_i}})$ contains all the feasible coalitions that
%include agent $a_i$ but no agent up $a_i$ in $PT$.

\begin{definition}[Required coalitions]
Given a game on a graph $CG= \allowbreak \langle A(G), v, F(G) \rangle $ and a
pseudotree $PT$ of $G$, we define the set of \emph{required} coalitions of a
local coalition $S\in \mathbf{S_i}$ of $a_i$, as $Req(S) = \bigcup_{j\in
Ch_i} Req(S,j)$ being $Req(S,j)$ recursively defined as:
\begin{equation*}
 Req(S,j) =
 \begin{cases}
  \emptyset & \text{ if } S\cap A(PT_j) = \emptyset \\
 % \bigcup_{j\in Ch_i} X^{r,S\cap T_j}_j & \text{ if } i\not\in S \\
  S' \cup \bigcup_{k\in Ch_j} Req(S\setminus S',k)& \text{ otherwise }
  \\
 \end{cases}
 \end{equation*}
 \noindent where $S' = arg \max_{\{S''\in \mathbf{S_j} \vert S'' \subseteq
 (S\cap A(PT_j))\}} \vert S''\cap S\vert$, that is the coalition in
 $\mathbf{S_i}$, strictly composed of variables in $S\cap A(PT_j)$, with maximum
 intersection with $S'$.
 \label{def:required_variables}
\end{definition}

%  \begin{definition}[Required variables]
% Given a game on a graph $CG= \allowbreak \langle A, v, F(G) \rangle $ and a pseudotree $T$ of $G$ over $A$, we
% define the set of required variables for a coalition $S$ as $X^{r}_{S} =
% X^{r,S\setminus \{i\}}_i$ being $X^{r,S}_i$ defined as:
%  \begin{equation}
%  X^{r,S}_i =
%  \begin{cases}
%   \emptyset & \text{ if } S = \emptyset \\
%  % \bigcup_{j\in Ch_i} X^{r,S\cap T_j}_j & \text{ if } i\not\in S \\
%   x_{S'} \cup \bigcup_{j\in Ch_i} X^{r,\{S\setminus S'\}\cap PT_j}_j& \text{
%   otherwise }
%   \\
%  \end{cases}
%  \end{equation}
%  \noindent where $S' = arg \max_{\{x_{S''}\in X_i \vert S'' \subseteq S\}} \vert
%  S''\cap S\vert$, that is the coalition in $X_i$, singly composed of variables
%  in $S$, with maximum
%  intersection with $S'$.
%  %that is the intersection between coalition graph $G_S$ and the coalition graph
%  %composed of all agents down $a_i$ in $PT$ (agents in $PT_i$).
% \label{def:required_variables}
% \end{definition}
%Observe that from the definition above the set of required coalitions is
%exhaustive ($\bigcup_{S'\in Req(S)} S'= S\cap D_i$) with respect to $S\cap D_i$
%and disjoint ($S',S'' \in Req(S): S'\cap S'' = \emptyset $).

In Figure \ref{fig:example_cycle_graph}, the set of \emph{required}
coalitions for coalition $\{012\}\in S_0$ is $Req(\{012\},a_1) = \{12\} \cup
Req(\{0\},a_2) = \{12\}$, whereas the set of \emph{required} coalitions for $\{02\}$ is
$Req(\{02\},a_1) = \emptyset \cup Req(\{02\},a_2) =\{2\}$.

%, whereas the set of required
%variables for $\{02\}$ is $X^{r}_{02} = X^{r,{2}}_1= X^{r,{2}}_2  = \{x_2\}$.
%PThen, the set of variables that require $\{12\}$ is $X^{\setminus r}_{12}
%=\{x_{012}\}$.
 
The intuition behind the concept of
\emph{required} coalitions is that an agent $a_i$ when aiming to form one of its local
coalition $S\in \mathbf{S}_i$ ensures the participation of
agents in $S$ down $a_i$ in $PT$ $(S\cap D_i)$, not directly through them
but by means of the set of \emph{required} coalitions $Req(S)$. Thus, agent
$a_0$ for its local coalition $\{012\}$ will not negotiate the participation of $a_2$
directly with him but instead $a_2$ will only negotiate with agent $a_1$ for
the (required) coalition $\{12\}$. Thus, $a_0$ \emph{delegates} to $a_1$ the
formation of a coalition that includes agents in $PT_1$. Thus, \emph{required}
coalitions allows agents to perform an structured negotiation based on the
graph because two agents would not need to negotiate directly if
they are not directly connected in $PT$.


Given this, our factor graph representation of a game on a graph is the
following:

%\textcolor{red}{here make connection with delegation\ldots}

%\textcolor{red}{can we briefly state why this is useful?}
%After definition \ref{def:required_variables}, we can define the set of
%variables that require a coalition variable $x_S$ from the sets of required
%variables $X^{\setminus r}_S = \{x_{S'} \vert x_{S} \in X^{r}_{S'}\}$.


\begin{definition}[Representation]
\label{def:representation}
 Given a game on a graph $CG=  \langle A(G), v, F(G)\rangle $ and a pseudotree
 $PT$ of $G$, we define a factor graph representation of $CG$ as
 $R(CG,PT)= \langle \mathcal{X}, \mathcal{F} \rangle$ where:

 \vspace{0.1in} \noindent . $\mathcal{X}=\{X_1 \cup \ldots \cup X_{\vert A
 \vert}\}$ is a set of binary variables, one per feasible coalition, that are
 partitioned in $\vert A \vert$ disjoint sets (one per agent). Similar to the concept of local
  coalitions, given an agent $a_i\in A$, its set of local variables $X_i$
  contains all the coalitions variables that include agent $a_i$ but no agent up
  $a_i$ in $PT$. Formally, $X_i = \{x_S\vert S \in F_{\{i\}}(G_{\setminus An_i})
   \}$.
%\textcolor{red}{Alternatively, Formally, $X_i = \{x_S \in \mathcal{X} \vert i
%\ni S\text{ and } S \cap \{PT\setminus PT_i\} = \emptyset\}$.}

\vspace{0.1in}\noindent .  $\mathcal{F}=\{F_1 \cup \ldots \cup F_{\vert A
\vert}\}$ is a set of functions that are partitioned in $\vert
  A \vert$ disjoint sets, one
per agent. Given an agent $a_i$, its set of local functions $F_i$ is composed
of:
% \begin{equation}
% F_i = u(X_i) \cup \hspace{-0.1in} \bigcup\limits_{x_S\in X_i}
% \hspace{-0.1in} v(x_S) \cup \hspace{-0.15in}\bigcup\limits_{\substack{x_S\in
% X_i \\ x_{S'}\in X^{\setminus r}_S}} \hspace{-0.15in} r(x_S,x_{S'}) \cup
% \hspace{-0.2in}\bigcup\limits_{\substack{x_S\in X_i \\ x_{S'},x_{S''}\in
% X^{\setminus r}_S}} \hspace{-0.2in}b(x_{S'},x_{S''})
% \end{equation}
	\begin{itemize}
  		\item $\{f_v(x_S) \vert x_S \in X_i \}$, a set of \emph{value functions},
  		one per variable in $X_i$, where a function $f_v(x_S)$
  		returns the value of coalition $S$ when $x_S=1$ 
  		($f_v(x_S=1)=v(S)$).
  		\item $f_{u}(X_i)$, a \emph{unique function} that controls that one and only
  		one of the variables $X_i$ set to $1$:
  		\begin{equation}
		 f_u(X_i)= 
		 \begin{cases} 
			 0,  \ \ \  \sum_{x_S \in X_i} x_{S} = 1  \\  
			 -\infty,  \ \ \mbox{otherwise}
		 \end{cases}
		 \end{equation}
	 	
	 	
\item A set of functions that capture the dependencies between each variable
$x_S\in X_i$ and the set of \emph{requiring} variables of $x_S$, $X^{\setminus
r}_S\subseteq X^{\setminus r}_i$. where $X^{\setminus r}_S$ stands for all the
variables corresponding to coalitions that require $S$ ($X^{\setminus r}_S = \{x_{S'}\vert S\in
Req(S')\}$) and $X^{\setminus r}_i$ stands for all the variables corresponding
to coalitions that require some coalition local to $a_i$ ($X^{\setminus
r}_i=\bigcup_{x_S\in X_i} X^{\setminus r}_S$). Formally for each $x_S\in X_i$,
the following sets of functions are included:
		
\noindent\Large.\normalsize   $\{f_r(x_S,x_{S'}) \vert x_{S'}\in X^{\setminus
r}_S \}$, a set of \emph{require functions}, one per requiring variable of
$x_S$. Given a requiring variable $x_{S'}\in X^{\setminus r}_S$ for $x_S$, the
\emph{require} function $f_r(x_S,x_{S'})$ controls that $x_{S'}$ is activated only if
its requested variable $x_{S}$ is also activated, substracting the value of
$x_{S}$ in this case. Formally,
		\begin{equation}
		f_r(x_{S},x_{S'})=
		\begin{cases}
		-\infty,  \   x_{S'} = 1 \mbox{ and } x_{S} = 0 \\
		-v(S),  \   x_{S'} = 1 \mbox{ and } x_{S} = 1 \\
		0,  \ \ \mbox{otherwise}
		\end{cases}
		\end{equation}
		
		
\noindent\Large.\normalsize   $\{f_b(x_{S'},x_{S''})\vert x_{S'},x_{S''}\in
X^{\setminus r}_S\}$ a set of \emph{blocking} functions, one per each pair of
variables that requested the same variable $x_S$. The
set of \emph{blocking} functions control that a most one of the coalitions variables
that require $x_S$ activates. Formally,
		 \begin{equation}
		 f_b(x_{S'},x_{S''})= 
		 \begin{cases} 
		 -\infty,  \ \ \  x_{S'} = 1 & x_{S''} = 1 \\  
		 0,  \ \ \mbox{otherwise}
		 \end{cases}
		 \end{equation}
	\end{itemize}
\end{definition}

Figure \ref{fig:representation_cycle_graph} shows this factor graph
representation for the game in Figure \ref{fig:example_cycle_graph} where circle
nodes stand for variables, square nodes stand for functions and each function
node is linked to all variables included in its scope. \emph{Unique} functions
are filled in black, \emph{require} in white and \emph{blocking} in grey whereas value functions are omitted
for the sake of clarity. Thus, for example, $X_{2}$ contains variables $x_1$ and
$x_{12}$, one per $a_2$'s local coalitions (those that
$a_2$ can form in $G$ with agents down $PT$). Then, a \emph{unique} function (included
in $F_1$) between $x_1$ and $x_{12}$ controls that exactly one of them is
activated. Finally, $F_1$ also contains two \emph{require} functions: one that encode
the dependency between $x_1$ and its requiring variable $x_{01}$ (linking $x_1$
and $x_{01}$) and another that encodes the dependency between $x_{12}$ and its
requiring variable $x_{012}$ (linking $x_{12}$ and $x_{012}$). The only \emph{blocking}
function in this example is contained as part of $a_3$'s local functions and
controls that at most one of the two variables that require $x_2$, $x_{12}$ and
$x_2$, is activated. Analogously, Figure \ref{fig:representation_line_graph} shows the factor graph representation but for the game in Figure
\ref{fig:representation_line_graph}.

Notice that by means of the \emph{require} functions this representation does not need
to create further dependencies between a variable $x_S\in X_i$, local to 
$a_i$, and any other variable local to an agent $a_j \in
S$ ($x_{S'}\in X_j\vert j\in S, j\neq i$), even if $S\cap S'\neq \emptyset$.
 For example, in Figure \ref{fig:representation_line_graph}, this
representation does not need to add any \emph{blocking} function between variables
$x_{01}$ and $x_{12}$, even when they share agent $a_1$, because the \emph{require}
function that exists between $x_{01}$ and $x_1$ indirectly blocks them (only one
variable is allowed to activate in $X_1$ and $x_{01}$ requires $x_1$ not
$x_{12}$). Similarly, there is no direct dependency between variables $x_{012}$
and $x_{1},x_{2}$, even if they share agents $a_1$ and $a_2$ respectively,
because $x_{012}$ requires the activation of $x_{12}$ in $X_1$ (\emph{blocking}
indirectly $x_{1}$) and $x_{12}$ requires the activation of $x_2$ in $X_2$
($x_{012}$ requires indirectly the activation of $x_2$ in $X_2$). Therefore, the
above proposed representation, 
efficiently encodes the dependencies that emerge among agents on a graph.


Given the representation of a $CG$ using the definition above, $R(CG,PT) =
\langle \mathcal{X}, \mathcal{F}\rangle$, its optimal solution is defined as  
$X^*= arg \max_{X} \sum_{f\in\mathcal{F}} f(X_f)= \mathcal{F}(X)$.
%PThen, the optimal solution of the factor graph representation $R(CG,PT) =
%\langle \mathcal{X}, \mathcal{F}\rangle$ is defined as $X^*= arg \max_{X}
%\sum_{f\in \mathcal{F}} f(X)$.
Now, assume we are given $X^*$, to recover the optimal coalition structure $CS^*$
in $CG$ need to define a mapping $\Omega$ between an assignment
of variables $X$ in $R(CG,PT)$ to a coalition structure in $CG$.



\begin{definition}[$\Omega$]
Given a representation $R(CG,PT)= \break \langle \mathcal{X},
\mathcal{F}\rangle$, $\Omega$ is a function that maps any assignment for any set
of variables $X\subseteq \mathcal{X}$ into a coalition structure $CS$ composed
of all coalitions $S$ activated in $X$ ($x_S=1\in X$) for which it does not
exist any other coalition $S'$ such that its coalition variable $x_{S'}$ is
activated in $X$ and that contains all agents in $S$ ($\nexists x_{S'}=1 \in X \text{ such that } S \subset S'$).
\end{definition}

Thus, the solution of the representation in Figure
\ref{fig:representation_line_graph}
$X^*=\{x_{0}=0,x_{01}=0,x_{012}=1,x_{1}=0,x_{12}=1,x_{2}=1 \}$ is mapped by
$\Omega$ to the optimal coalition structure $CS^*$ of the corresponding game in
\ref{fig:example_line_graph}, $\Omega(X^*)=\{\{012\}\}$.








Then, the following Theorem \ref{th:correctness_cgm} proves that given mapping
$\Omega$, the representation $R(CG,PT)$ where $CG=\langle A(G), v, F(G)\rangle$ is correct (the optimal
solution of $R(CG,PT)$ identify the optimal coalition structure in $CG$,
$\Omega(X^*)=CS^*$). 


\begin{theorem}[Correctness of the representation]
Given a game on a graph $CG=\langle A(G), v, F(G)\rangle$ and a
pseudotree $PT$ of $G$, the representation $R(CG,PT)=\langle
\mathcal{X}, \mathcal{F} \rangle$ is correct: $\forall_{X\vert
\mathcal{F}(X) \neq \infty }:\Omega(X) \in \mathbf{CS}\ \& \ \mathcal{F}(X) = v(\Omega(X))$.
\label{th:correctness_cgm}
\end{theorem}

\begin{proof}
Considering the definition of mapping $\Omega$, to prove that $\forall_{X\vert
\mathcal{F}(X) \neq \infty }:\Omega(X) \in \mathbf{CS}$ we only need to prove
that any pair of variables activated in a valid\footnote{A solution is valid when it does not violate any hard constraint:
$\sum_{f\in\mathcal{F} } f(X)\neq \infty$.} solution $X$ $x_S=1, x_{S'}=1 \in X$ satisfy one of the following
conditions: (i) $S \cap S' = \emptyset$; or (ii) $S \subset S'$; or (iii) $S' \subset S$.
Let's prove this by contraction. Let's assume that two variables
$x_S\in X_i$, $x_{S'}\in X_j$ such that $S\cap S'\neq \emptyset$ are set to $1$
in a valid configuration $X$ but $S \not\subset S'$ nor $S' \not\subset S$.


Case $i = j$ clearly leads to a contradiction because function $f_u(X_i)\in
\mathcal{F}$ restricts that only one variable in $X_i$ is set to 1.


Consider now the case $i\neq j$.  Notice that, due to the recursive nature of
\emph{require} functions, the activation of a variable $x_S$ not only requires the activation of
variables corresponding to the \emph{required} coalitions of $S$, but also of
variables corresponding to the \emph{required} coalitions of the \emph{required}
coalitions of $S$ and so on. For example, in Figure
\ref{fig:representation_cycle_graph}, the activation of $x_{012}$ directly requires the activation of $x_{12}$ but also the
activation of $x_2$ (indirectly required through coalition $\{12\}$).
Let $X^{Act}_S$ be the set of variables recursively required for the activation
of $x_S$. $X^{Act}_S$ contains a coalition $x_{S''}\in X_k$, that we refer to as
$x^{Act,k}_S$, per agent $k\in S$ where $S''\subseteq S$ stands for the local
coalition of $a_k$ with maximum intersection with $S$ ($S'' = arg \max_{\{x_{S_i}\in X_i \vert S_i \subseteq
S\}} \vert S_i\cap S\vert$). Then, $X^{Act}_S$ and $X^{Act}_{S'}$, contain, for
each $k\in S'\cap S$, one coalition in $X_k$. Now from here we will distinct two
cases. Consider that $\exists k\in S'\cap S$ such that $x^{Act,k}_S$
and $x^{Act,k}_{S'}$ are different
($x^{Act,k}_{S}\neq x^{Act,k}_{S'}$). This leads to a contradiction because $f_u(X_k)$
restricts that only one variable can be set to 1 at $X_k$. This is the case in
Figure \ref{fig:representation_cycle_graph} of coalitions $x_{01}$ and $x_{12}$,
the two respective coalitions overlap in agent $a_1$ but in $X_1$ variable
$x_{01}$ requires $x_{1}$ whereas $x_{12}$ requires $x_{12}$. Now consider the
remaining case in which $\forall k\in S'\cap S : x^{Act,k}_S=x^{Act,k}_{S'}$. 
Let $x_{S''}=x^{Act,k}_S=x^{Act,k}_{S'}$. Then in this case, that
means that $\exists k\in S'\cap S$, $\exists$ $l\in S'\setminus S$ and $m \in S \setminus S'$ such that
$x^{Act,l}_S,x^{Act,m}_{S'} \in X^{\setminus r}_{S''}$ leading to a contradiction because function
$f_b(x^{Act,l}_S,x^{Act,m}_{S'})$ blocks the joint activation of $x^{Act,l}_S$
and $x^{Act,m}_{S'}$. For example, in Figure \ref{fig:example_cycle_graph}
variables $x_{12}$ and $x_{02}$, that overlap on agent $a_2$, require the
activation of the same variables in $X_2$, namely $X^{Act,2}_{\{12\}} =
X^{Act,2}_{\{02\}} = \{x_{2}\}$
$X^{Act,1}_{\{12\}}=x_{12}$, $X^{Act,0}_{\{02\}}=x_{02}$ and $x_2\in Req(\{12\})$, $x_2\in
Req(\{x_{02}\})$, a \emph{blocking} function exists between $x_{12}$ and $x_{02}$.
Thus, we proved that for any $X$, $\forall_{X \vert \mathcal{F}(X)\neq \infty}
\Omega(X)\in \mathbf{CS}$.

Now to prove Theorem \ref{th:correctness_cgm} it only remains to show that
$\forall_{X\vert \mathcal{F}(X) \neq \infty } \break \mathcal{F}(X) =
v(\Omega(X))$. Since value functions $\{v(x_S) \vert x_S\in \mathcal{X}\}$ add the value of
all coalitions whose coalitional variable is set to 1 in $X$ ($\sum_{x_S=1
\in X} v(S)$) we only need to prove that for any pair of variables $x_S,x_{S'}$
activated in $X$ such that $S'\subset S$, the value of $S'$ is
substracted. In any valid solution $X$, if $x_S$ and $x_{S'}$ are activated
being $S'\subset S$, that means that $S'\in X^{Act}_S$ and since by sequentially
application of \emph{require} functions starting from $x_S$ the value of all 
variables in $X^{Act}_S\setminus \{x_S\}$ is substracted, Theorem
\ref{th:correctness_cgm} holds.
% 
% \textcolor{red}{extra stuff}
% Notice that in this
% representation any solution $X$ in order to be
% valid has to satisfy the restrictions imposed by \emph{require} and blocking functions.
% thus, for each variable $x_S$ that is set to 1 in $X$
% all its \emph{require}d variables are activated and all its blocking variables are
% not. Notice however that requisite functions define a set of restrictions
% recursively, an for each variable $x_S$ activated in $X$ must also activate not
% only the variables corresponding to the \emph{require}d coalitions of $S$, but also the
% variables corresponding to the \emph{require}d variables of these and so on. 
% Thus any $x_S=1 \in X_i$ must also activate by recursively applying requisite
% functions, a set of other variables down $PT_i$, that we denote as
% $X^{Act}_{S}$. $X^{Act}_{S}$ is a set composed of $\vert S \vert$ variables, one
% $x_{S'}\in X_i$ per agent in $S$, where $S'\subseteq S$ stands for coalition
% local to $a_i$, with maximum intersection with $S$ ($S' = arg \max_{\{x_{S''}\in
% X_i \vert S'' \subseteq S\}} \vert S''\cap S\vert$). Thus, in Figure , the set
% of variables $X^{Act}_{012}$, is composed
% of $x_{12}$, the variable corresponding to the \emph{require}d coalition of $\{012\}$,
% but also by recursively applying \emph{require} functions, of $x_{2}$, the variable
% corresponding to the \emph{require}d coalition of $\{12\}$.
\end{proof}



Thus, given a game over a graph $CG=\langle A(G),v,F(G)\rangle$ under the
proposed representation you can use an algorithm from GDL family, as the one reviewed in Section \ref{sec:gdl_message_passing}, to allow agents to identify the optimal coalition structure in $CG$. Since GDL algorithms
are executed over a JT, next we formulate a particular JT for $R(CG,T)$.

\begin{definition}[$\gamma$]
\label{def:gamma}
Let $\gamma$ be a function that given a game on a graph $CG=\langle A(G), v,
F(G)\rangle$ and a pseudotree $PT$ of $G$ maps them to a JT
$\gamma(CG, PT)=\langle \mathcal{C}, \Psi, \mathcal{S} \rangle$, where:
\begin{itemize}
  \item $\Psi = \{\psi_i \vert a_i\in A\}$ contains one potential per
   agent in $A$, where $\psi_i(X_{\psi_i})$ is defined as the
   combination of functions $F_i$ ($F_i$ defined as in
   Def. \ref{def:representation}). Then, 
   $X_{\psi_i}=\bigcup_{f\in F_i} X_f = \{ X_i \cup X^{\setminus r}_i\}$.
   \item $\mathcal{C} = \{X_{C_i} \vert a_i\in A\}$ contains one clique per
   agent in $A$, where $X_{C_i}= X_{\psi_i} \cup \bigcup_{j\in Ch_i}
   X_{C_j} \setminus X_j$.
   \item $\mathcal{S}$ contains one separator
   $Sep_{ij}$ per pair of cliques $X_{C_i}$ and $X_{C_j}$
   such that $a_j$ is parent of $a_i$ in $PT$. As in Def.
   \ref{def:junctiontree}, a separator $Sep_{ij}$ includes the
   intersection of cliques $X_{C_i}$, $X_{C_j}$  and hence, in this case $Sep_{ij}= X_{C_i}\setminus X_i$. 
 \end{itemize} 
\end{definition}
In this formulation we assume the cliques of $\gamma(CG, PT)$
distributed among agents such that each agent $a_i\in A$ is assigned a single
clique $X_{C_i}$ and hence, the GDL scheme among cliques is
indeed a message-passing scheme among agents in $PT$.

% and that the set of
%cliques $\mathcal{C}= \{X_{C_1},\ldots,X_{C_n}\}$ is distributed among a set of
%agents $A=\{a_1,\ldots,a_{n}\}$, where each agent $a_i\in A$ is assigned a
%single clique $X_{C_i}$. Given a factor graph $\langle \mathcal{X},\mathcal{F}
%\rangle$, Action-GDL runs in two phases: a first phase that runs a
%single-vertex GDL message-passing over the junction tree; and a second value
%propagation phase that retrieves the optimal solution $X^*$.
Figure \ref{fig:treedecomposition_line_graph} shows the $\gamma$-JT
for the game in Figure \ref{fig:example_line_graph} whose circles stand for
cliques and edges (between cliques) stand for separators. Since the graph of
this game is acyclic, the clique of any agent $a_i\in A$, $X_{C_i}$, is
equal to the scope of its potential, $X_{\psi_i}$. Thus, $X_{C_i}$ is composed
of $a_i$'s local variables and all the local variables of $a_i$'s parent whose
corresponding coalition contains $a_i$ ($\{x_S\in X_{p_i} \vert a_i\in S\}$).
Thus, since $a_0$ is the root, its clique and potential's scope is strictly
composed of its local variables, namely
$X_{C_0}=X_{\psi_0}=\{x_0,x_{01},x_{12}\}$ whereas the clique and potential
scope of $a_1$ is composed of its local variables, $\{x_1,x_{12}\}$, and all
variables local to its parent $a_0$ whose corresponding coalition contains
$a_1$, namely $\{x_{01},x_{012}\}$. In contrast, the $\gamma$-JT for
the game in Figure \ref{fig:example_cycle_graph} depicted in Figure
\ref{fig:treedecomposition_cycle_graph} whose graph contains a cycle, the
potential scope of agent $a_2$ contains, in addition to $a_2$'s local
variables, variables that are not local to its parent, namely $x_{02}$ that is
local to $a_0$ (and not to $a_1$). Moreover, in this cyclic case the clique of
an agent may contain more variables than the ones in its potential. For
example, the clique of agent $a_1$ contains, in addition of 
$X_{\psi_1}$, variable $x_{02}$. This variable is included in $a_2$'s clique in
order to satisfy the running intersection. Notice
that, in general to enforce the running intersection agents might have
to manipulate \emph{extra} variables that refer to coalitions of agents they do
not know directly (i.e., with which they do not share a direct link in $G$).
However, agents will never decide to activate a coalition in which they do not
participate, as they never change the value of such \emph{extra} variables but
merely propagates demand for agents down the pseudotree to participate in such
coalition and decision of agents up the pseudotree on whether such coalitions
should be formed.


\noindent\begin{proposition}
\noindent$\gamma(CG, PT)$ is a junction tree for $R(CG, PT)$.
\label{prop:valid_tree_decomposition}
\end{proposition}
\begin{proof}
 We prove proposition \ref{prop:valid_tree_decomposition} by showing
how $\gamma(CG, PT)$ satisfies the required \emph{covering} and \emph{running
intersection} properties. Since $\forall a_i \in A: X_{\psi_i} \subseteq
X_{C_i}$, $\{F_1 \cup \ldots \cup F_{\vert A \vert}\}=\mathcal{F}$ and
$\forall_{i,j\in A} F_i\cap F_j = \emptyset$, covering is satisfied. Then, by
Def. \ref{def:required_variables}, $\forall x_S\in X_i$ $X^{\setminus
r}_S$ does not contain any variable local to any descendant of $a_i$ in $PT$.
Thus, any variable $x_S\in X_i$ does not appear in any set $X^{\setminus r}_j$
of any agent $a_j$ ancestor of $a_i$ in $PT$ and does not need to be included by
the running intersection to any clique of any ancestor of $a_i$. Then, for
each $a_i\in A$ the inclusion of $\bigcup_{j\in Ch_i}
X_{C_i} \setminus X_j$ that contains by recursion all the variables that
required some variable down $a_i$ ($\bigcup_{a_j\in D_i}X^{\setminus r}_j$),
excluding all variables local to agents down $a_i$ ($\bigcup_{a_j\in D_i}X_j $)
satisfies the running intersection.
\end{proof}
\noindent Hence, given a game $CG=\langle A(G), v, F(G) \rangle$
and a pseudotree $PT$ of $G$ the execution of the GDL over
$\gamma( CG, PT )$, recovers the optimal solution $X^*$ of $R(CG, PT)$ and
hence, by mapping $\Omega$, the optimal coalition structure in $CG$. The
complexity of this algorithm comes directly from GDL and it is
$\mathcal{O}(2^{\vert X_{C_m} \vert})$ where is $X_{C_m}$ is the largest clique
in $\gamma( CG, PT )$. 
Observe that GDL is executed over a junction tree $\gamma( CG, PT )$ in which
each agent is assigned a clique and a potential. Hence,
unlike other approaches in the literature, a node here is not an agent but a
(potential) function, which encodes agent local knowledge, and a set of (clique)
variables, that control which local coalitions an agent is willing to
form.

 Next, in Section \ref{sec:csg_on_graphs} we
will show how, by considering the underlying structure of the representation and the junction tree mapping of the
coalitional game, this complexity can be dramatically reduced.



% More generally, given a game on a graph $CG=\langle A(G), v, F(G) \rangle$ and a
% pseudotree $PT$ of $G$ over $A(G)$, after the single-vertex GDL
% execution over $\gamma( CG, PT )$ is over, the \emph{state}
% function of each agent $a_i\in PT$ recovers the value of the optimal
% coalition structure $CS^{*,i}$ of a subgame $CG^i$:
% \begin{equation}
% \hspace{-0.02in}\max_{X_{C_i}} s_i(X_{C_i}) =
% \max_{X_{C_i}}\max\limits_{\mathcal{X}\setminus X_{C_i}} \bigotimes_{j\in
% A(PT_i)}\hspace{-0.01in} \psi_i(X_{C_i}) =v(CS^{*,i})
% \label{eq:gdl_2_optimal_coalition_structure}
% \end{equation}
% where $CS^{*,i}$ stands for the best
% coalition structure that agent $a_i$ and agents down $a_i$ in $PT$ can form
% among themselves, using a subset of coalitions of $CG$ that do not contain any
% agent up $a_i$ in $PT$. Hence, the state function of each agent $a_i\in PT$
% recovers the value of the optimal coalition structure $CS^{*,i}$ of the subgame
% $CG^i= \langle A(PT_i), v, F(G_{A(PT_i)}) \rangle$ composed of all the agents
% in $PT_i$ (of $a_i$ and its descendants in $PT$) and all the feasible coalitions in $CG$
% excluding those coalitions that require some agent up $a_i$ in $PT$ (that contain some ancestor of $a_i$).
% In the particular case where $a_i=a_r$ root agent $a_r$, $v(CS^{*,r}) =
% v(CS^*)$ and the state function of $a_r$ recovers the optimal coalition
% structure in $CG$.


% At the root agent, the state function recovers the value of the optimal
% coalition structure of CG:
% \begin{equation}
% \max_{X_{C_i}} s_r(X_{C_r}) = \max_{X_{C_r}}\max\limits_{\mathcal{X}\setminus
% X_{C_r}} \sum\limits_{i\in A} \psi_i(X_{C_i}) =v(CS^{*})
% \label{eq:gdl_2_optimal_coalition_structure_root}
% \end{equation}



% After the single-vertex GDL execution is over, the \emph{state} function
% of each agent $a_i\in A$ is $s_i(X_{C_i}) = \max\limits_{\mathcal{X}\setminus
% X_{C_i}} \sum\limits_{j\in A(PT_i)} f_i(X_{C_i})$ and, consequently,
% 
% \begin{equation}
% \max_{X_{C_i}} s_i(X_{C_i}) = \max_{X_{C_i}}\max\limits_{\mathcal{X}\setminus
% X_{C_i}} \sum\limits_{j\in A(PT_i)} f_i(X_{C_i}) =v(CS^{*,i})
% \label{eq:gdl_2_optimal_coalition_structure}
% \end{equation}
% where $CS^{*,i}$
% is the optimal coalition structure of $CG^i = \break \langle A(PT_i), v,
% F(G_{\setminus An_i})\rangle$. Notice that $CG^i$ uses a subset of
% feasible coalitions of $CG$, those that do not contain
% any agent up $a_i$ in $PT$, while being exhaustive and disjoint with respect to
% agents in $A(PT_i)$. Notice that in the traditional setting $A=A(G)$, $CG^i =
% \langle A(PT_i), v, F(G_{A(PT_i)})\rangle$ and $CS^{*,i}$ stands for the best
% coalition structure that agent $a_i$ and agents down $a_i$ in $PT$ can create by
% themselves in $CG$.
% After the single-vertex GDL execution is over, for any agent $a_i\in
% A:\Omega(X^{*,i}) = CS^{*,i}$ were the solution $X^{*,i}=\bigcup_{j\in
% A(PT_i)}X^{*,i}_{C_j} $ is obtained by recursively applying:
% $X^{*,i}_{C_j} = arg \max\limits_{X_{C_j},Sep_{jp}=X^{*,i}_{C_p}} s_j(X_{C_j})$.
%\begin{equation}
%CS^*_{T_i} = \Omega()
%\end{equation}
% \begin{observation}
%  After the execution of the single-vertex GDL algorithm over a tree
%  decomposition $\langle T, \mathcal{F} \rangle$ of $CR(CG)$ the state of an
%  agent is $b_i(X_{C_i})= \max_{\mathcal{X}_i\setminus X_{C_i}}
%  \mathcal{F}_{i}(X_{C_i})$ where $CG_i = \langle T_i, v, F(G_{T_i})\rangle$
%  and $\langle T_i,\mathcal{F}_i,\mathcal{X}_i\rangle$  is a junction tree
%  over $CR(CG_i)$. Consequently, $\max_{X_{C_i}}b_i(X_{C_i})=v(CS^*_{T_i})$
%  where $CS^*_{T_i}$ is the solution of $CG_i$.
% \end{observation}


% well-known message passing techniques from the GDL family
%some existing distributed optimization algorithms in the literature
% In particular, our approach builds upon well-known message passing
%techniques from the GDL family which we extend to the non-cooperative setting
%in order to, not only compute, but also incentive agents to form the optimal
%coalition structure.
%We exploit this novel representation to extend some existing
%distributed optimization algorithms in the literature to the non-cooperative
%setting in order to, not only compute, but also incentive agents to form the
%optimal coalition structure.
%Algorithm \ref{proc:preprocessing} allows agents in a game $CG$ over
%a graph $G$ to distributedly arrange into a junction tree of $R(CG,PT) $.


\vspace{-0.1in}\section{Decentralised Coalition Structure Generation On Graphs}
\label{sec:csg_on_graphs}

%In general settings, such
%algorithm is dominated by the computational effort required to perform the
%maximization tasks, and thus it is exponential in the size of the biggest
%clique of the junction tree. However, notice that in our specific setting hard
%constraints limit the possible coalitions that each agent must consider.
%Moreover, some of the hard constraints we are dealing with essentially require
%that only one variable over $n$ must be activated (see the $f_u$ functions in
%Section \ref{sec:representation}). This kind of constraints are usually easy to
%check (i.e., they do not require considering all possible configurations of
%variables involved) therefore the complexity of our algorithm could be
%significantly reduced. 


\noindent In this section we show how to reduce the complexity of the GDL
algorithm when executed over $\gamma(CG, PT)$ to find the optimal coalition structure of the
coalitional game $CG$ by exploiting the structure of the potentials we form (see Definition \ref{def:gamma}). 
%the coalitional game
%problem and of our proposed representation.
Concretely, we observe that, given a game $CG$ on a graph $G$ and a
pseudotree $PT$ of $G$, the potential of any agent $a_i\in A$,
$\psi_i(X_{\psi_i})$, has an special structure that dramatically limits the set
of $X_{\psi_i}$'s valid assignments. In particular we can show that the following observation holds:

\begin{observation}
The local memory and the computation required by each agent $a_i\in A(G)$ on the
execution of the single-vertex GDL algorithm over $\gamma(CG,PT)$ is linear to
its clique's size ($\mathcal{O}(\vert X_{C_i}\vert)$).
\label{obs:complexity_on_trees}
\vspace{-0.1in}
\end{observation}
To see this, recall that by Def. \ref{def:gamma} $X_{\psi_i}$ is composed of $a_i$'s local
variables, $X_i$, and the set of requiring variables of $a_i$'s local variables,
$X^{\setminus r}_i$. 
For example, in Figure \ref{fig:treedecomposition_cycle_graph} $a_2$'s
potential, $\psi_2(X_{\psi_2})$, is defined over its local variables,
$X_2=\{x_2\}$ and the requiring variables for $\{x_2\}$, $X^{\setminus r}_{\{2\}}= \{x_{12},x_{02}\}$. Moreover, recall that $\psi_i$ is the
combination of functions in $F_i$.
 Then, by function $f_u\in F_i$, any valid
configuration of $X_{\psi_i}$ is restricted to activate exactly one
variable in $X_i$. Also, by inclusion of \emph{require} functions,
the activation of any requiring variable $x_{S'}\in \bigcup_{x_S\in X_i}
X^{\setminus r}_S$ forces variable $x_S\in X_i$ to be set to 1, and hence,
any other variable in $X_i$ set to 0. Similarly, any two requiring variables
that require different variables in $X_i$ are indirectly blocked and can not be
jointly activated. Finally, by \emph{blocking}
functions block the joint activation of any two requiring variables that require
the same variable $x_S$ in $X_i$, $x_{S'},x_{S''}\in X^{\setminus r}_S$.
As a result, the set of $X_{\psi_i}$'s valid assignments in
$\psi_i$ contains: (i) one assignment per local variable $x_S \in X_i$ in which
$x_S$ is set to $1$ and the rest of variables to $0$; (ii) one
assignment per requiring variable $x_{S'} \in X^{\setminus r}_S$ such that $x_{S'}$ and its required variable $x_{S'}$ are set to $1$ and the rest of variables to $0$.

Thus, in $\gamma(CG,PT)$ the size of $\psi_i(X_{\psi_i})$ is linear with
respect to the number of variables in its scope ( $\vert X_{\psi_i}\vert$) and
not exponential as in general JTs. For example, in Figure
\ref{fig:treedecomposition_cycle_graph} $\psi_2(X_{\psi_2})$ contains three
valid assignments, one per variable in $X_{\psi_2}$, namely
\small$\{x_2\hspace{-0.03in}=\hspace{-0.03in}1,x_{12}\hspace{-0.03in}=\hspace{-0.03in}0,x_{02}\hspace{-0.03in}=\hspace{-0.03in}0\}$\normalsize,\small$\{x_2\hspace{-0.03in}=\hspace{-0.03in}1,x_{12}\hspace{-0.03in}=\hspace{-0.03in}1,x_{02}\hspace{-0.03in}=\hspace{-0.03in}0\}$\normalsize
and
\small$\{x_2\hspace{-0.03in}=\hspace{-0.03in}1,x_{12}\hspace{-0.03in}=\hspace{-0.03in}0,x_{02}\hspace{-0.03in}=\hspace{-0.03in}1\}$\normalsize.

Hence, the memory and the computation required by each agent $a_i\in A$ to
compute messages (Eq. \ref{eq:gdl_message}), state function (Eq.
\ref{eq:gdl_state_function}) and clique's optimal values (Eq.
\ref{eq:cliques_variables_computation}) in an execution of GDL over $\gamma(CG,
PT)$ is not exponential to the clique's size ($\mathcal{O}(2^{\vert
X_{C_i}\vert})$) but rather exponential to the clique's size excluding variables
in its potential ($\mathcal{O}(\vert X_{\psi_i}\vert 2^{\vert X_{C_i} \setminus
X_{\psi_i}\vert})$). Next, observe that, in the particular case of a coalition
game $CG$ on an acyclic graph $G$ we have that $X_{C_i} = X_{\psi_i}$. This is
because, since $G$ does not contain any cycle, cliques do
not contain any of the extra variables that are in general required to ensure the
running intersection. This leads to a complexity linear to the clique's
size and hence, the execution of GDL over a $\gamma-$JT of $CG$
allows agents to find the optimal coalition structure, $CS^*$, on a complexity
linear to the set of variables in $CG$, that is the number of feasible
coalitions in $CG$.


% Notice that since the set of
%variables $X_{C_i} \setminus X_{\psi_i}$ are the ones needed to satisfy the
%running intersection property, indeed the number of variables in is directly
%related to the induced treewidth of the PT of the agent interaction graph and
%to the treewidth of G.
%The width of a tree decomposition is the size of the largest clique minus one.
%Exponential to the with of a JT.

%Observe that, given a game $CG$ over an acyclic graph $G$, then: (i) any rooted
%version of $G$ is a pseudotree $PT$ of $G$; and (ii) building on $PT$, each
%agent $a_i\in A(G)$ only has access to other agents down $PT$ through its
%children $Ch_i$. Therefore, for any agent $a_i\in A(G)$, the set of requiring
%coalitions, $Req(S)$, of any of its local coalitions, $S\in
%\mathbf{S_i}$ is composed of coalitions local to its children ($Req(S)\subseteq \bigcup_{j\in Ch_i}
%\mathbf{S}_j$) and the set of requiring
%variables $X^{\setminus r}_i$ is a subset of the local variables from
%its parent, $a_p$, in $PT$ ($X^{\setminus r}_i\subseteq X_p$).
%Let $X_{ip}$ be the set coalitions variables local to
%agent $a_p$ whose corresponding coalition contains agent $a_i$ $\{x_S\in
%X_p \vert i\in S\}$. Thus, in acyclic graphs, $\forall a_i\in A(G):X_{\psi_i}=X_i\cup X_{ip}$ where $a_p$ stands for the
%parent of $a_i$ in $PT$, and since agents do not need to propagate any variable
%to satisfy the running intersection property, $\forall a_i\in
%A(G):X_{C_i}=X_{\Psi_i}\cup X_{ip}$. Thus, the time and space complexity of the
%single-vertex GDL in this case is linear to the size of the largest clique in
%$\gamma(CG,PT)$.

Finally, we observe that when single-vertex GDL is executed over
$\gamma(CG,PT)$ we can draw some connections between the messages exchanged up
the tree, the state functions computed by agents and the corresponding
coalitional game $CG$.
Specifically, the \emph{state}
function of each agent $a_i\in PT$ recovers the value of the optimal
coalition structure $CS^{*,i}$ of a subgame $CG^i$:
\begin{equation}
\hspace{-0.02in}\max_{X_{C_i}} s_i(X_{C_i}) =
\max_{X_{C_i}}\max\limits_{\mathcal{X}\setminus X_{C_i}} \bigotimes_{j\in
A(PT_i)}\hspace{-0.01in} \psi_i(X_{C_i}) =v(CS^{*,i})
\label{eq:gdl_2_optimal_coalition_structure}
\vspace{-0.05in}
\end{equation}
where $CS^{*,i}$ stands for the best
coalition structure that agent $a_i$ and agents down $a_i$ in $PT$ can form
among themselves, using a subset of coalitions of $CG$ that do not contain any
agent up $a_i$ in $PT$. Hence, the state function of each agent $a_i\in PT$
recovers the value of the optimal coalition structure $CS^{*,i}$ of the subgame
$CG^i= \langle A(PT_i), v, F(G_{A(PT_i)}) \rangle$ composed of all the agents
in $PT_i$ (of $a_i$ and its descendants in $PT$) and all the feasible coalitions in $CG$
excluding those coalitions that contain some ancestor of $a_i$.
%In the particular case where $a_i=a_r$ root agent $a_r$, $v(CS^{*,r}) =
%v(CS^*)$ and the state function of $a_r$ recovers the optimal coalition
%structure in $CG$.

Moreover, the message that each agent $a_i$ exchanges with its parent $a_p$ during the execution of the single-vertex GDL, satisfy that:
\begin{equation}
\mu_{i\rightarrow
p}(Sep_{ip}) = v(CS^{*,i\setminus S})
\label{eq:message_2_optimal_coalition_structure}
\vspace{-0.05in}
\end{equation}
where $S$ is the coalition formed by
variables activated in $Sep_{ip}$ where $v(CS^{*,i\setminus S})$ the value of the best coalition structure agents down
$A(PT_i)$ can form \emph{without} agents in $S$ (a variable activated
in $Sep_{ip}$ stands for an agent up $PT_i$ requiring a set of another
agents down $PT_i$ essentially preventing them to form any other coalition).
 
%Notice, that $\forall x_S\in Sep_{ip}$, $x_S$ stands for
%a variable local to an agent $a_k$ up $a_i$ in $PT$ that require a variable $x_{S'}$ local to some agent $a_j$ down $a_p$ in $PT$. Then, when $x_S$ is set to 1, that stands for agent $a_k$ requiring the participation, and since coalitions are disjoint the
%exclusivity, of other agents in $S$ to join coalition $S$. Thus, the value of
%agents down the tree for that configuraiton is the value of the best coalition
%structure agents in $A(PT_i)$, excluding agents in $S$, can form among
%themselves.






% \begin{proposition}
% \label{prop:message_to_optimal_coalition_structure}
% Given a game on a graph $CG=\langle A(G), v,F(G) \rangle$ and a pseudotree $PT$
% of $G$, the message $\mu_{i\rightarrow p}$ exchanged between an agent $a_i$ and
% its parent $a_p$ during execution of the single-vertex GDL algorithm over
% $\gamma(CG,PT)$ satisfies that $ \mu_{i\rightarrow p}(Sep_{ip}) =
% v(CS^{*,i\setminus S})$ where $S= \bigcup_{x_{S'}=1 \in Sep_{ip}} S'$ and
% $CS^{*,i\setminus S}$ is the optimal coalition structure of $CS^{i \setminus
% S}=\langle A(PT_i)\setminus S, v, F(G_{A(PT_i)\setminus S})\rangle$ (the
% best coalition structure disjoint and exhaustive with respect to agents in $T_i$ restricted to be composed of feasible coalitions in
% $CG$ that do not contain any agent up $a_i$ in $T$ or in $S\cap A$).
% \end{proposition}
% \begin{proof}
% By definition \ref{def:tree_decomposition}, the set of clique variables of 
% $a_i$ is composed of its local variables ($X_i$), the set of variables of
% agents up $a_i$ in $T$ that require some variable in $X_i$ ($X^{\setminus
% r}_i$) and a subset of variables from its children clique variables
% ($\bigcup_{j\in Ch_i} X_{C_i}\setminus X_j $).
% Moreover each agent $a_k\in A$ filters out its local variables ($X_k$) when
% sending a message to its parent in $T$ and hence, $Sep_{ip}$ can not contain any
% local variable from any agent down $a_i$ in $T$ ($\forall_{x_S\in
% Sep_{ip}, k\in T_p}: x_S\not\in X_k$). Then, $\forall x_S\in Sep_{ip}$
%  $x_S$ stands for a variable from an agent up $a_i$ in $T$ ($\exists a_k \in
% \bar{T_i}: x_S\in X_k$) that require the activation of a variable $x_{S'}$
% ($x_{S'}\in X^{\setminus r}_S$) from
% an agent $a_k$ in $T_i$ ($\exists_{a_k\in T_i}: x_{S'} \in X_k$)
% and hence $x_S=1\in Sep_{ip}$ stands for agent $a_k$ up to $a_i$ requiring
% exclusivity of the set of agents in $S\cap A$ (coalition structures are disjoint
% with respect to agents in $A$). Thus, the best coalition structure that
% agents in $T_i$ can compose without agents up $a_i$ in the $T$ when fixing
% $x_S\in Sep_{ip}$ to $1$ is restricted to not contain any coalition $x_{S'}\in F(G_{\setminus {\bar{T_i}}})$ such that $S \cap S' \cap A \neq
% \emptyset$.
% %  and because $CG_i$ is exhaustive
% % and disjoint with respect to agents in $T_i$ that also means any coalition $x_S\in
% % F(G_{\setminus {\bar{T_i}}})$ such that $S\cap T_i\neq \emptyset$ can not be
% % form. The activation of $S'$ means that  you can not use these agents to
% % form any coalition.
% \end{proof}


Next, in Section \ref{sec:algorithm_stable_on_trees} we extend this GDL
scheme to the non-cooperative setting in order to, not only compute, 
but also incentive agents to form the optimal coalition structure on tree
graphs.


\vspace{-0.1in}\section{Decentralised Stable Coalition Formation on Trees}
\label{sec:algorithm_stable_on_trees}

%\section{Algorithms}
%\label{sec:algorithms}

\noindent In this section we detail how the single-vertex GDL algorithm
detailed in Section \ref{sec:csg_on_graphs}, can be extended to provide
core-stable coalition structures in the particular case of games defined over acyclic graphs (trees). 
This extension, that so-called \emph{SCF-Trees} algorithm, allows agents to
compute on acyclic graphs, simultaneously with the optimal coalition structure, a set of
payments that incentivise agents to form such structure, without increasing the complexity of
the single-vertex GDL algorithm.

As the single-vertex GDL, SCF-Trees requires a
preprocessing phase, in which agents compile the game $CG=\langle
A(G),v,F(G)\rangle$ into a $\gamma(CG,PT)$ where, since $G$ is
a tree, $PT$ is any rooted version of $G$. Although this requires agents
to build, using a distributed procedures, cliques $X_{C_i}$ and potentials $\Psi_i$
described in Section \ref{sec:representation} here, the description of such
procedure is not described here due to the lack of space.
Once agents have built such structure, following the GDL single vertex
algorithm, the \emph{SCF-Trees}
algorithm, is
composed of two main phases: i) \emph{demand propagation phase} (see Algorithm
\ref{proc:demandpropagation}) where agents compute and propagate up the tree
payment demands associated to each possible coalition they can join with agents
up the tree; ii) \emph{value propagation phase} (see Algorithm
\ref{proc:valuepropagation}) where agents decide which coalition to join and propagate their decision down the
tree.

In what follows we detail these two phases by using
as a example a run of the SCF-Trees algorithm over the $\gamma$-junction
tree in Figure \ref{fig:treedecomposition_line_graph} of the game on
a tree shown in Figure \ref{fig:example_line_graph}.
%Both approaches require the agents involved in the game $CG$ to compile the
%factor graph $R(CG,PT)$ into a junction tree\footnote{When dealing with acyclic
%graphs agents only need to decide a root for the tree.}. This requires agents
%to build, using a distributed procedures, cliques $X_{C_i}$ and potentials
%$\Psi_i$ described in Section \ref{sec:representation}. Such procedure simply
%involves message passing between the agents over the PseudoTree arrangement
%$PT$ but is not reported here due to lack of space.



\begin{algorithm}[!tb]
\caption{\textbf{DemandPropagation}} 
\small Each $a_i$ knows $\langle a_p, X_i,
Ch_i,\psi_i\rangle$ and runs:\normalsize
\small
 \begin{algorithmic}[1] 
	\FORALL{$a_j \ \in Ch_i$}
        \STATE Wait for the demand message $d_{j \rightarrow i}(Sep_{ji})$ from
        $a_j$;
    \ENDFOR
     \STATE $p_i(X_{C_i}) =  \psi_i(X_{\psi_i}) \otimes \bigotimes_{j \in Ch_i}
     d_{j \rightarrow i}(Sep_{ji});$ /*Compute payment function*/
     \STATE $\rho_i = \max_{X_{C_i}} p_i(X_{C_i});$
     /*$a_i$ computes its payment */
    \IF{$a_i$ is not the root /*Compute $a_p$' demand message*/}
    	\STATE $d_{i \rightarrow p}(Sep_{ip})= \max\limits_{X_i}
    	p_i(X_{C_i}) - \rho_i ;$ 
    	 \STATE Send $d_{i\rightarrow p}(Sep_{ip})$ to $a_p$;
    \ENDIF 
    \RETURN $\langle p_i(X_{C_i}),\rho_i,\bigcup_{j\in Ch_i}Sep_{ji} \rangle$
\end{algorithmic}
\label{proc:demandpropagation}
\vspace{-0.03in}
\end{algorithm}

\begin{algorithm}[!tb]
\caption{\textbf{ValuePropagation}} 
\small $\text{Each } a_i \text{ knows } \langle
a_p,p_i(X_{C_i}),Ch_i,\{Sep_{ji}\}\rangle\text{ and runs:}$
\small
\begin{algorithmic}[1]
	\IF{$a_i$ is not the root}
  		\STATE  Wait for $Sep^*_{ip}$ from $a_p$;
    \ENDIF
     \STATE $X^*_{C_i} = \arg \max\limits_{X_{C_i}, Sep_{ip} = Sep^*_{ip} }
  	     p_i(X_{C_i});$ /*Compute best solution, slicing with respect the
  	     parent decision*/
    \FORALL{$a_j \in Ch_i$ /*Send coalition variables' values to each child*/ }
        \STATE Send $Sep^*_{ji}\leftarrow X^*_{C_i}\cap Sep_{ji}$ to $a_j$;
    \ENDFOR
    \RETURN $X^*_{C_i}$
\end{algorithmic}
\label{proc:valuepropagation}
\vspace{-0.03in}
\end{algorithm}


% \begin{algorithm}[!tb]
% \caption{\label{Alg:stableCoalitionOnTrees}\textbf{SCF-Trees
% ( $\langle A, v, F(G) \rangle$ )} } 
% Each $a_i$ knows $\langle v, F_{_{\{i\}}}(G)\rangle$ and runs: 
% \begin{algorithmic}[1]  
% 	\STATE \textbf{/*Preprocessing phase*/}
% 	\STATE \textbf{Pseudotree arrangement}- run token based mechanism that arrange
% 	agents into a pseudotree $PT$ -- At completion, $a_i$ knows $a_p,Ch_i,PT_i$;
% 	\STATE \textbf{Junction tree arrangement}- run message-passing algorithm that
% 	arrange agents into a junction tree $\gamma(CG,PT)$--At completion, $a_i$ knows
% 	$X_i,\psi_i$; \STATE \textbf{/*Demand propagation phase*/}
% 	\STATE $\langle p_i(X_{C_i}),\rho_i,\{Sep_{ji}\}
% 	\rangle \leftarrow$DemandPropagation($a_p,X_i,Ch_i,\psi_i$); 
% 	\STATE \textbf{/*Value propagation phase*/}
% 		\STATE $X^*_{C_i} \leftarrow$
% 		ValuePropagation($a_p,p_i(X_{C_i}),Ch_i,\{Sep_{ji}\}$); \RETURN $\langle
% 		\rho_i, \Omega(X^*_{C_i})  \rangle$
% \end{algorithmic}
% \end{algorithm}

%\textcolor{red}{high level algorithm description}

%First, agents start with a preprocessing phase (line 2, \emph{TreeDecomposition}
%procedure) that compiles the problem into a junction tree of the compact
%representation (see section \ref{sec:representation}) to be used in the
%following two phases. In the preprocessing phase, agents arrange the 
%graph into a pseudotree $PT$. 

%Figure \ref{fig:representations_line_graph} the  tree of the game
%in Figure \ref{fig:example_line_graph} is rooted at $a_0$. Then each agent $a_i$
%creates one binary variable $x_S$, along with a function with its value $v_S$,
%for each possible coalition that $a_i$ can join with agents down the tree. For example,
%in Figure \ref{fig:representations_line_graph} $a_0$ creates three
%variables, namely $x_{0}$, $x_{01}$, $x_{012}$.
%Notice that the set composed of all these variables is $X_i$ (e.g. $X_0 =
%\{x_{0}, x_{01}, x_{012}\}$). 
%Then, each agent $a_i$ waits for its parent's message that contains a set of
%tuples where each tuple is composed of a coalition up the tree $x_S$ that
%require a set of agents $S'$ in $A(PT_i)$. In an acyclic graph, these variables
%are singly composed of all parent's variables that contain $a_i$ ($X_{pi}$).
%Then, for each variable $x_S\in X_{pi}$, each agent $a_i$ creates a require
%function between $x_S$ and $x_{G_{S'} \cap G_{A(PT_i)}}$. Thus, in Figure
%\ref{fig:representations_line_graph}, $a_1$ after receiving $\{\langle
%x_{01},{1}\rangle, \langle x_{012} ,\{1,2\}\rangle\}$ from $a_0$ creates two
%require functions, namely $r(x_{01},x_{1})$ and $r(x_{012},x_{12})$.
%Then, each agent $a_i$ communicates to each of its children $a_j\in Ch_i$ a
%message that contains for each set of variables that include $a_j$,
%$x_S \in X_{ij}$, a tuple with $x_S$ and the set of agents from $S$ reachable
%from $a_j$, $S\cap A(PT_j)$. 
%The intuition is that each agent $a_j$ would act as a mediator negotiating the
%payment demanded by agents down $PT_i$ to join a coalition $x_S$ with
%$a_i$.
%Finally, each agent computes its local function $f_i$ as the combination of: (i)
%function $u_i$ that controls that one and only one of $X_i$ coalition
%variables is activated (set to 1); (ii) value functions $\vec{v}$; and (iii)
%require functions $\vec{r}$ (note that in acyclic  graphs the set of
%blocking functions is empty).
%%$Sep_{ji}=\{x_S\in X_i \vert S \ni j\}$.
%%When an agent $a_i$ receives the set of coalitions $Sep_{pi}$ from its
%%parent, $a_i$ creates a \emph{require} relation for each $x_S\in Sep_{pi}$
%%and the coalition $x_{G_S \cap G_{T_i}} \in X_i$ (that is the coalition
%%composed of $a_i$ and all agents down $a_i$ in $T$ also included in $S$). 
%Hence, at the end of this preprocessing phase, each agent knows: (i) $X_i$;
%(ii) $\bigcup_{x_S\in X_i} X^{\setminus r}_S$ that in a tree is all the
%variables of $a_p$ that includes $a_i$ ($X_{ip}$); and (iii) local function
%$f_i$. 
%After this first processing phase is over, $SCF-Trees$
%runs two phases:
%\begin{itemize}
%  \item A \emph{demand propagation phase} (line , \emph{DemandPropagation}
%  procedure), in which agents exchange demand messages up the tree.
%  \item An \emph{offer propagation phase} (line , \emph{ValuePropagation}
%  procedure), in which agents exchange offer messages down the tree.
%\end{itemize}

When executing the \emph{demand propagation} protocol, each agent $a_i$ waits
until receiving a \emph{demand} message from each of its children $a_j \in Ch_i$
(lines 1-3). The \emph{demand} message that $a_j$ sends to its parent $a_i$
contains for each of the coalition variables $x_S$ in $Sep_{ji}$ the amount
required for $a_j$ and agents down $a_j$ in $PT$ to join coalition $S$. For
example, in Figure \ref{fig:representation_line_graph}, agent $a_0$ waits until
receiving the \emph{demand} message from $a_1$ that contains a function over
variables in their separator $\{x_{01},x_{012}\}$. Upon receiving all
\emph{demand} messages, each agent $a_i$ computes its \emph{payment function}
$p_i$ as the combination of function $\psi_i$, that combines its local utility
and restrictions for variables $X_{\psi_i}$, and the \emph{demand} messages from
the children, that subtract the amount required for agents down $a_i$ (line 4).
Then, $a_i$ computes its \emph{payment} $\rho_i$ as the highest payment $a_i$
can get on any of its variable configurations (which stand for local $a_i$'s
coalitions). After that, if agent $a_i$ has a parent in $PT$ (lines 6-8), $a_i$
sends a message to its parent $a_p$ that summarizes its \emph{payment function}
$p_i$ over all possible configurations of variables in $Sep_{ip}$, subtracting its own
\emph{payment} $\rho_i$. The result of this summarization is for each coalition
variable $x_S$ in $Sep_{ip}$ the payment required from agents in $A(PT_i)$ to
join $S$. Thus, in Figure \ref{fig:representation_line_graph}, $a_1$ summarizes
its payment function $p_1$ over variables $\{x_{01},x_{012}\}$ (filtering out
$X_1=\{x_1,x_{12}\}$). Then, agents proceed to execute the value propagation
phase by executing the \emph{value propagation} protocol (depicted in
Algorithm \ref{proc:valuepropagation}).

During the \emph{value propagation} protocol, each agent $a_i$ waits until
receiving a \emph{value} message from its parent $a_p$ (lines 1-3). Such message
specifies whether $a_p$ is willing to pay the amount requested by agents in
$A(PT_i)$ so that they will join a coalition $x_S\in Sep_{ip}$. For example, in
Figure \ref{fig:representation_line_graph}, $a_1$ waits until receiving a
message from $a_0$ with its decision with respect to coalitions
$x_{01},x_{012}$. Then, $a_i$ computes the best coalition it can join given the
decision of its parent $a_p$ (line 4). If $a_p$ decided to create a coalition
$x_S\in Sep_{ip}$ and thus is willing to pay agent the amount requested by $a_i$
and other agents ($S'$) down the tree to join $S$, then the best coalition for
$a_i$ is $x_{S'}$. In contrast, if $a_p$ does not activate any variable $x_S\in
Sep_{ip}$, $a_i$ will select the best coalition
 $a_i$ can join that includes itself and some agents down $a_i$ in
the tree. Finally, agent $a_i$ sends an \emph{value} message to each of its
children $a_j \in Ch_i$ that contains which coalition $x_S\in Sep_{ij}$ $a_i$ accepted to
create, if any (line 5-7).



\subsection{Complexity and Correctness}
In this subsection, we formally
assess the complexity and correctness of the SCF-Trees
algorithm. However, for convenience, first we formalise the relationship of
SCF-Trees with single-vertex GDL by means of the following Lemma.

\begin{lemma}[\emph{DemandProtocol-GDL equivalence}]
\label{lem:demandprotocolgdl_equivalence}
Given a game on a graph $CG = \langle A(G), v, F(G)\rangle $ and a
pseudotree $PT$ of $G$, the execution of the DemandProtocol and the
single-vertex GDL over $\gamma(CG,PT)$ are equivalent \footnote{Equivalent
here stands for equality but performing a different normalisations of
functions/messages (adding/substracting a normalisation constant).}, namely
agents: exchange equivalent$^5$ messages ($\forall_{a_i\in A(G)}: d_{i
\rightarrow p}(Sep_{ip})= \mu_{i \rightarrow p}(Sep_{ip}) - \rho_{A(PT_i)}$);
and compute equivalent$^5$ payment and state functions ($\forall_{a_i\in A(G)}:
p_i(X_{C_i})  = s_i(X_{C_i}) - \sum_{j\in D_i}\rho_{j}$).

\end{lemma}

\begin{proof}
First, from Equation \ref{eq:gdl_message} and Procedure
\ref{proc:demandpropagation} we can directly state that the value of the demand message $d_{i \rightarrow
p}(Sep_{ip})$ that an agent $a_i\in A(G)$ exchanges with its parent $a_p$ in
$\gamma(CG,PT)$ during the execution of the DemandProtocol over $\gamma(CG,PT)$
is equal to the value of the message $\mu_{i \rightarrow
p}(Sep_{ip})$ exchanged between these agents in the single-vertex GDL
substracting all the payments of agents in $PT_i$ ($\forall_{a_i\in A(G)}: d_{i
\rightarrow p}(Sep_{ip})= \mu_{i \rightarrow p}(Sep_{ip}) - \rho_{A(PT_i)}$).
Second, observe that given the above message equivalence, the payment function
computed in the DemandProtocol as $p_i(X_{C_i}) =_{\textrm{Proc.}
\ref{proc:demandpropagation} } \psi_i(X_{\psi_i}) \otimes  \bigotimes_{j \in Ch_i} d_{j \rightarrow
i}(Sep_{ji})$ can be expressed in terms of single-vertex GDL messages as
$p_i(X_{C_i})= \allowbreak \psi_i(X_{\psi_i}) \otimes \bigotimes_{j \in Ch_i} ( \mu_{j \rightarrow
 i}(Sep_{ji}) - \sum_{k\in PT_j} \rho_k) =_{\text{Eq.
 \ref{eq:gdl_state_function}}}\allowbreak s_i(X_{C_i}) - \sum_{j\in D_i}\rho_{j}$.
 Thus, the computation of the payment function of an agent $a_i\in A(G)$ in the
 DemandProtocol is equal to the state function in single-vertex GDL
 with exception of the normalisation that substracts the payments of
 all agents down $a_i$ in $PT_i$.
\end{proof}

\noindent Then, given Lemma \ref{lem:demandprotocolgdl_equivalence}, we can
directly assess the complexity of SCF-Trees from the complexity of the
single-vertex GDL algorithm (see Observation \ref{obs:complexity_on_trees}) as:
the memory and the computation required by each agent $a_i\in A(G)$ on the execution of SCF-Trees algorithm over $\gamma(CG,PT)$ is linear to its clique's size ($\mathcal{O}(\vert X_{C_i}\vert)$).

 
\noindent Finally, the correctness of SCF-Trees algorithm is assessed by the
following Theorem.

\begin{theorem}
Given a game on a graph $CG = \langle A(G), v, F(G)\rangle $ where $G$ is
acyclic, the outcome produced by SCF-Trees$(CG)$ belongs to the core of $CG$.
\label{th:StableCoalitionFormationOnTrees_correctness}
\end{theorem}

\begin{proof} 
By Lemma \ref{lem:demandprotocolgdl_equivalence} (\emph{DemandProtocol-GDL equivalence}) the payment function $p_i(X_{C_i})$ computed by $a_i\in
A(G)$ during the execution of the DemandProtocol over the $\gamma(CG,PT)$ is equal to the state function $s_i(X_{C_i})$ computed during
the execution of the single-vertex GDL algorithm over $\gamma(CG,PT)$ up to a
normalisation constant (the sum of the payments of all the descendants of $a_i$
in $PT$). Then,
the set of optimal clique variables in both algorithms is
the same and the value propagation phase in SCF-Trees computes a solution $X^*$
that recovers the optimal coalition structure, $CS^*$, of $CG$
($\Omega(X^*)=CS^*$).
Hence, to prove Theorem \ref{th:StableCoalitionFormationOnTrees_correctness} we
only need to show that the allocation $\rho$ computed by agents $A(G)$ during the execution of the DemandProtocol satisfy the two core
conditions, namely: ($CS^*$-Imputation) $\sum_{i\in A(G)}\rho_i=v(CS^*)$; and
(Group rationality)  $\forall S \subseteq F(G): \rho_S \geq v(S)$.
By Lemma \ref{th:for_general_graphs_sum_of_payments}
(\emph{$CS^{*,i}$-Imputation}), by setting $a_i$ to the root agent $a_r$ in
$PT$, we have that $\rho$ is an imputation of $CS^{*,r}$ where $CS^{*,r}$ is the
optimal coalition structure of $CG^r=\langle A(PT), v,F(G_{A(PT)})\rangle$
and, since $A(PT)=A(G)$, $\rho$ is an
imputation of $CS^*$. By Lemma
\ref{th:algorithm_on_trees_satisfies_all_constraints} (\emph{Allocation on
Trees is group rational}), $\rho$ is group rational.
Thus, the outcome of SCF-Trees $(\Omega(X^*),\rho)$ belongs to the core of $CG$
and Theorem \ref{th:StableCoalitionFormationOnTrees_correctness} holds.
\end{proof}



% \begin{observation}[\emph{GDL messages equivalence}]
% From equation \ref{eq:gdl_message} and Procedure \ref{proc:demandpropagation}
% we observe that given a game on a graph $CG = \langle A(G), v, F(G)\rangle $ and
% a pseudotree $PT$ of $G$, the message that an agent $a_i$
% exchanges with its parent $a_{p}$ in the single-vertex GDL protocol and
% in the DemandPropagation protocol satisfy that: $\forall_{Sep_{ip}}:
% \allowbreak \mu_{i \rightarrow p}(Sep_{ip}) = d_{i \rightarrow p}(Sep_{ip}) +
% \rho_{A(PT_i)}$.
% \label{obs:gdl_equivalence_messages}
% \end{observation}
%   
% \begin{lemma}[\emph{GDL state function equivalence}]
% Given a game on a graph $CG = \langle A(G), v, F(G)\rangle $ and a
% pseudotree $PT$ of $G$,  the payment function $p_i(X_{C_i})$ computed
% by any agent $a_i\in A$ satisfy that $\forall_{X_{C_i}}: p_i(X_{C_i})=
% s_i(X_{C_i}) - \sum_{j\in D_i}\rho_{j}$ where $\rho_j$ is the
% payment of agent $a_j$ and $s_i(X_{C_i})$ is the state function of $a_i$ in the
% execution of the single-vertex GDL algorithm over $\gamma(CG,PT)$.
% \label{lem:gdl_equivalence_function}
% \end{lemma}
% \begin{proof}
% $p_i(X_{C_i}) =_{\textrm{Proc.} \ref{proc:demandpropagation} }
% \psi_i(X_{\psi_i}) \otimes  \bigotimes_{j \in Ch_i} d_{j \rightarrow
% i}(Sep_{ji}) = \allowbreak
%  \psi_i(X_{\psi_i}) \otimes \bigotimes_{j \in Ch_i} ( \mu_{j \rightarrow
%  i}(Sep_{ji}) - \sum_{k\in PT_j} \rho_k) =_{\text{Eq.
%  \ref{eq:gdl_state_function}}}\allowbreak s_i(X_{C_i}) - \sum_{j\in D_i}\rho_{j}$.
% \end{proof}

\begin{lemma}[\emph{$CS^{*,i}$-Imputation}]
Given a game on a graph $CG = \langle A(G), v, F(G)\rangle $ and a
pseudotree $PT$ of $G$, the allocation computed by agents $A(G)$
during the execution of the DemandPropagation 
over $\gamma(CG,PT)$ satisfy that $\forall a_i\in A$: $\sum_{j\in A(PT_i)}\rho_j =
v(CS^{*,i})$, where $CS^{*,i}$ is the optimal coalition structure of $CG^i=\langle A(PT_i), v,F(G_{
A(PT_i)})\rangle$.
\label{th:for_general_graphs_sum_of_payments}
\end{lemma}
\begin{proof}
$\rho_i =_{\text{Proc. \ref{proc:demandpropagation}}} max_{X_{C_i}}p_i(X_{C_i})
=_{\text{Lem. \ref{lem:demandprotocolgdl_equivalence}} }
\max_{X_{C_i}} s_i(X_{C_i}) -
\sum_{j\in D_i}\rho_j =_{\text{Eq.
\ref{eq:gdl_2_optimal_coalition_structure}} } v(CS^{*,i})  -
\sum_{j\in D_i}\rho_j$ and Lemma
\ref{th:for_general_graphs_sum_of_payments} holds.
\end{proof}







% \begin{proposition}
% \label{prop:simplification_computation_payment_trees}
%  Given a game on a graph $CG=\langle A(G), v,F(G)\rangle$ where $G$ is acyclic
%  and a pseudotree $PT$ of $G$, the payment of any
% agent $a_i\in A$, $\rho_i$, computed by the DemandPropagation over
% $\gamma(CG,PT)$ satisfy:
% \begin{equation}
% \begin{array}{l l}
% \rho_i  &= 
% \max\limits_{X_{C_i}} p_i(X_{C_i})  \\ &
% =  \max\limits_{X_{\psi_i}}
%  \psi_i(X_{\psi_i}) \otimes \bigotimes_{j \in Ch_i}  \mu_{j \rightarrow
%  i}(X_{ji}) - \rho_{A(PT_j)}\\ &  \substack{ =  \\ 
% \text{Lem.}
%  \ref{th:for_general_graphs_sum_of_payments}  }
%   \max\limits_{S\in F_{\{i\}}(G)}
% v(S) + \sum\limits_{j \in Ch_i} v(CS^{*,j\setminus S}) -
% v(CS^{*,j})
% \end{array}
% \notag
% \end{equation}
%Notice that we can ignore the set $X_{ip}$ in the computation of $\rho_i$
%because the value of activating any $x_S\in X_{ip}$ is lower than the value of
%the configuration that only activates its requested variable $x_{S'}\in X_i$
%(when $x_S=1$ the corresponding require function substracts the value of
%$x_{S'}$).
%\end{proposition}

\begin{lemma}[Allocation On Trees is Group Rational]
Given a game over an \emph{acyclic graph} $CG = \langle A(G), v, F(G)\rangle $
and a pseudotree $PT$ of $G$ over $A(G)$, the allocation computed by agents during the
execution of the DemandPropagation over
$\gamma(CG,PT)$ satisfy that: $\forall a_i \in A: \forall S \subseteq
F(G_{A(PT_i)}):\rho_S \geq v(S)$.
\label{th:algorithm_on_trees_satisfies_all_constraints}
\end{lemma}



\begin{proof}
We prove Lemma \ref{th:algorithm_on_trees_satisfies_all_constraints} by
induction on $d$, the rank of agent $a_i$ in $PT$. In the base case  $d=1$
($a_i$ is a leaf) since the only coalition that $a_i$ can compose by itself,
$X_i = \{x_{\{a_i\}}\}$, and by Lemma
\ref{th:for_general_graphs_sum_of_payments}, $\rho_i = v(\{a_i\})$. In the
induction case we can split the pseudotree into the root agent and a set of
subtrees of lower depth. Then, consider an agent $a_i$ whose rank is $n+1$ and
assume that Lemma \ref{th:algorithm_on_trees_satisfies_all_constraints} holds
for all agents whose rank is less than or equal to $n$ in the tree ($\forall a_j
\in Ch_i  \ \forall S \in F(G_{A(PT_j)}): \rho_S \geq v(S)$). Then, to prove
Lemma \ref{th:algorithm_on_trees_satisfies_all_constraints}, we only need to
show that $\forall S \in F_{\{i\}}(G_{A(PT_i)}): \rho_S \geq v(S)$. Recall that
the payment of $a_i$ computed in the DemandProtocol satisfies that $\rho_i=
\max_{X_{C_i}} p_i(X_{C_i}) = \allowbreak \max_{X_{\psi_i}}
 (\psi_i(X_{\psi_i}) \otimes \bigotimes_{j \in Ch_i}  \mu_{j \rightarrow
 i}(X_{ji}) - \rho_{A(PT_j)}) =_{Eq.
 \ref{eq:message_2_optimal_coalition_structure}} \max_{S \in
 F_{\{i\}}(G_{A(PT_i)})} v(S) + \sum_{j \in Ch_i} v(CS^{*,j\setminus S}) -
 \sum_{j \in Ch_i} \rho_{A(PT_j)} $. Thus,  when computing its payment on a
 coalition $S$, $a_i$: (i) substracts to
the value of $S$ the payment of all agents down $a_i$ in $PT$; and (ii) adds,
for each child $a_j\in Ch_i$ the value of the best coalition structure agents in
$A(PT_j)$ can compose without agents in $S$ ($v(CS^{*,j\setminus S})$). Since,
as we will prove next $\forall_{j \in Ch_i}: v(CS^{*,j\setminus
S})=\rho_{A(PT_j)\setminus S}$, (ii) adds the payment of all the agents down
$a_i$ not in $S$. As a result, when computing its payment in each coalition $S$,
$a_i$ is substracting to the value of $S$ the payment of all other agents in
$S$, $\rho_i= \max_{S \in F_{\{i\}}(G_{A(PT_i)})} v(S) -\rho_{S\setminus \{i\}}
$, and since $\rho_i$ is computed as the maximum among all payments $a_i$ can
get on local coalitions, the group rationality condition $\forall S \in
F_{\{i\}}(G_{A(PT_i)}): \rho_{S\setminus\{i\}} +\rho_i \geq v(S)$ is satisfied.

We prove that $\forall{j \in Ch_i}:$ $v(CS^{*,j\setminus
S})=\rho_{A(PT_j)\setminus S}$ by observing that: (i) since $G$ is acyclic, $S$
forms a continuous subtree down $a_i$, so if we exclude agents $S$ from $PT_j$
the result is a set of subtrees $\{PT_l\}$ where $a_l$ stands for the agent with
highest level in branch $l$ not included in $S$ and $PT_l$ includes all the
agents down $a_l$ in $PT$; and (ii) by Lemma
\ref{th:for_general_graphs_sum_of_payments}, $\forall \{PT_l\}:
v(CS^{*,l})=\rho_{PT_l}$.
\end{proof}
 
          


\section{Conclusions and Future Work}
\label{sec:conclusions}
In this paper we propose a novel graphical model representation scheme for
coalitional games on graphs. We provide a mapping between
our graphical model representation and the original coalitional game and prove the
correctness of such mapping. 
We have also show how by building on this novel representation you can use
existing GDL algorithms to allow agents to compute the optimal
coalition structure of any coalitional games on a graph. Then, for the
particular case of games on acyclic graphs (trees), we formulate an extension of
the GDL message-passing algorithm that allow agents not only to form the
optimal coalition structure but also an allocation of payments in the core of
the game.

Future work in this
space include two main directions: 
first, we aim to exploit our graphical model representation of coalitional games
on graphs to devise extensions of GDL message-passing algorithms that can
identify stable coalition structures (or detect core emptyness) on general
graphs (e.g. extending the presented SCF-Trees algorithm to deal with graphs
with cycles). Second, we intend to perform an empirical analysis of our approach to assess its applicability in a realistic problem setting, such as for example stable coalition formation in the smart grid.
%Second, we intend to explore approximate approaches in the context
%of stable coalition formation, building on GDL-based approximate solution
%algorithms (e.g., max-sum and Generalized Belief Propagation).


%this We then show how our representation can be used to devise decentralised
%algorithms for formation of core-stable coalition structures. Specifically, we
%extend well-known message passing algorithms from the GDL family to identify
%stable coalition structures (or detect core emptiness) on games defined over
%trees.  

%\include{proofs}
%\input{proofs}
\small
\bibliography{aamas2012}
\bibliographystyle{abbrv}
\end{document}
